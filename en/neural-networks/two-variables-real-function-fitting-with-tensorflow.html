

<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head lang="en">
		<meta http-equiv="content-language" content="en">
		<meta name="author" content="Ettore Messina">	

		<style>
			#cookiescript_checkbox_input {
				-moz-appearance: checkbox;
				-webkit-appearance: checkbox;
				-ms-appearance: checkbox;
				appearance: checkbox;
				opacity: 1.0;
			}
			#cookiescript_checkbox_text {
				color: white;
			}
			#cookiescript_description a:hover {
				color: yellow !important;
			}
		</style>
		<script type="text/javascript" charset="UTF-8" src="https://cookie-script.com/s/19e1626ea9f21a6fcc285b559b5957e6.js"></script>
		<script type="text/plain" data-cookiescript="accepted" data-cookiecategory="performance" src="https://www.googletagmanager.com/gtag/js?id=UA-149444322-1"></script>
		<script type="text/plain" data-cookiescript="accepted" data-cookiecategory="performance">
			window.dataLayer = window.dataLayer || [];
			function gtag(){dataLayer.push(arguments);}
			gtag('js', new Date());
			gtag('config', 'UA-149444322-1', { 'anonymize_ip': true });
		</script>


		<title>Two-variables real-valued function fitting with TensorFlow</title>
		<meta name="description" content="To fit a function of two variables by observing different multilayer perceptron models with TensorFlow without writing code but only via the command line." >
		<meta name="keywords" content="machine learning, deep learning, neural network, tensorflow, multilayer perceptron, mlp, fitting, approximate, regression, function, two variables, surface, activation, training, loss, optimization, command line" >
		<link rel="canonical" href="https://computationalmindset.com/en/neural-networks/two-variables-real-function-fitting-with-tensorflow.html" />
		<link rel="alternate" hreflang="en" href="https://computationalmindset.com/en/neural-networks/two-variables-real-function-fitting-with-tensorflow.html" />
		<link rel="alternate" hreflang="it" href="https://computationalmindset.com/it/reti-neurali/approssimazione-di-una-funzione-reale-di-due-variabili-con-tensorflow.html" />
		
    <!-- SCHEMA.ORG JSON-LD WEBSITE -->
    <script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "WebSite",
        "name": "Computational Mindset",
        "url": "https://computationalmindset.com/",
        "sameAs": ["https://www.facebook.com/ComputationalMindset/", "https://github.com/ettoremessina/"],
        "author":
        {
          "@type": "Person",
          "name": "Ettore Messina",
          "image": "https://computationalmindset.com/images/ettore-messina.jpg",
          "gender": "Male",          
          "sameAs": ["https://www.facebook.com/ettore.messina.73/", "https://www.instagram.com/etmessina/", "https://twitter.com/ettoremessina/", "https://twitter.com/Computational_M/", "https://github.com/ettoremessina/", "https://medium.com/@ettoremessina/", "https://www.linkedin.com/in/ettoremessina", "https://www.linkedin.com/company/computational-mindset"]
        }
    }
    </script>

		
    <script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BreadcrumbList",
        "itemListElement":
        [
		
          {
            "@type": "ListItem",
            "position": 1,
            "item":
            {
                "@id": "https://computationalmindset.com/en/",
                "name": "Computational Mindset"
            }
          },
		
          {
            "@type": "ListItem",
            "position": 2,
            "item":
            {
              "@id": "https://computationalmindset.com/en/neural-networks/",
              "name": "Neural Networks"
            }
          },

          {
            "@type": "ListItem",
            "position": 3,
            "item":
            {
              "@id": "https://computationalmindset.com/en/neural-networks/two-variables-real-function-fitting-with-tensorflow.html",
              "name": "Two-variables real-valued function fitting with TensorFlow"
            }
		  }
		
        ]
    }
    </script>
		

		<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/railscasts.min.css">
		<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>
		
		<script>hljs.initHighlightingOnLoad();</script>
		<style>
			pre > code 
			{
				font-size: 1.2em;
			}
		</style>

		
		<script type="text/javascript" src="https://latex.codecogs.com/latexit.js"></script>
		<script type="text/x-mathjax-config">
			MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
		</script>
		<script type="text/javascript"
			src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>



		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../../assets/css/main.css" />
		<link rel="shortcut icon" href="../../favicon.ico" type="image/x-icon" />
		<link rel="icon" href="../../favicon.ico" type="image/x-icon" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="../../en/info.html" class="logo"><strong>Computational&nbsp;Mindset</strong> by&nbsp;Ettore&nbsp;Messina</a>
									<div style="text-align:right">
										<a class="logo" href="../../en/">en</a>
										&nbsp;&nbsp;&nbsp;
										<a class="logo" href="../../it/">it</a>
									</div>
									<ul class="icons">
										<li><a href="https://github.com/ettoremessina/" class="icon brands fa-github" target="_blank"><span class="label">GitHub</span></a></li>
										<li><a href="https://www.linkedin.com/company/computational-mindset" class="icon brands fa-linkedin" target="_blank"><span class="label">LinkedIn</span></a></li>
										<li><a href="https://twitter.com/Computational_M/" class="icon brands fa-twitter" target="_blank"><span class="label">Twitter</span></a></li>
										<li><a href="https://www.facebook.com/ComputationalMindset/" class="icon brands fa-facebook-f" target="_blank"><span class="label">Facebook</span></a></li>
										<li><a href="https://www.youtube.com/c/ComputationalMindset" class="icon brands fa-youtube" target="_blank"><span class="label">YouTube</span></a></li>
										<li><a href="https://medium.com/@ettoremessina/" class="icon brands fa-medium-m" target="_blank"><span class="label">Medium</span></a></li>
										<li><a href="https://linktr.ee/ComputationalMindset/" class="fas fa-link" style="color: grey;" target="_blank"><span class="label"></span></a></li>
									</ul>
								</header>

<!-- Content -->
	<section>
		<header class="main">
			<h1>Two-variables real-valued function fitting with TensorFlow</h1>
		</header>

		<p>
			This post is part of a series of posts on the fitting of mathematical objects (functions, curves and surfaces) through a <em>MLP</em> (Multi-Layer Perceptron) neural network;
			for an introduction on the subject please see the post <a href="../../en/neural-networks/fitting-with-multi-layer-perceptrons-highly-configurable.html">Fitting with highly configurable multi layer perceptrons</a>.<br />
			<br />
			The topic of this post is the fitting of a continuous and limited real-valued function of two variables constrained in a rectangle $$f(x,y) \colon [a,b]\times[c,d] \to \rm I\!R$$ with a MLP
			so that the user can test different combinations of MLP architectures, their own activation functions, training algorithm and loss function without writing code
			but working only on the command line of the four Python scripts which separately implement the following features:

			<ul>
				<li>
					<em>Dataset generation</em>
				</li>
				<li>
					<em>MLP architecture definition + Training</em>
				</li>
				<li>
					<em>Prediction</em>
				</li>
				<li>
					<em>Visualization of the result</em>
				</li>
			</ul>

			The related code requires the version 3 of Python and it uses TensorFlow 2 technology (for both CPU or GPU) with Keras (that is integrated inside TensorFlow 2); it requires also NumPy and MatPlotLib libraries.<br/>
			To get the code please see the paragraph <a href='#downloadcode'>Download of the complete code</a> at the end of this post.<br/>
			<br/>
			The exact same mechanism was created using PyTorch technology; see the post <a href="../../en/neural-networks/two-variables-real-function-fitting-with-pytorch.html">Two-variables real-valued function fitting with PyTorch</a> always published on this website.<br />
			If you are interested in regression of a real function of two variables with machine learning techniques see the post
			<a href="../../en/machine-learning/fitting-with-configurable-xgboost.html">Fitting functions with a configurable XGBoost regressor</a>.
		</p>

		<h2>Dataset generation</h2>
		<p>
			Goal of the <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/two-variables-function-fitting/fxy_gen.py" target="_blank"><code>fxy_gen.py</code></a> Python program
			is to generate datasets (both training and test ones) to be used in later phases;
			it takes in command line the function of two variables to be approximated (in <em>lambda body</em> syntax), the rectangular subset of domain (specifing the two intervals of the sides of the rectangle) and discretization step
			and it generates the dataset in an output csv file applying the function to the passed rectangle.
			<br/>
			In fact the output csv file has three columns (without header): first two columns contain the values of independent variables $x$ and $y$ within the passed rectangle discretized by discretization step;
			thrid column contains the values of dependent variable, ie the values of function $f(x,y)$ correspondent to values of $x$ and $y$ of first two columns.
			<br/>
			<br/>
			To get the program usage you can run this following command:
			<pre><code class="shell">$ python fxy_gen.py --help</code></pre>
			and the output got is:
			<br/>
			<br/>
			<pre><code class="shell">usage: fxy_gen.py [-h] 
-h, --help                  show this help message and exit
--dsout DS_OUTPUT_FILENAME  dataset output file (csv format)
--fxy FUNC_X_BODY           f(x,y) body (body lamba format)
--rxbegin RANGE_BEGIN       begin x range (default:-5.0)
--rxend RANGE_END           end x range (default:+5.0)
--rybegin RANGE_BEGIN       begin y range (default:-5.0)
--ryend RANGE_END           end y range (default:+5.0)
--rstep RANGE_STEP          step range (default: 0.01)</code></pre>
			Please read the file <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/two-variables-function-fitting/README.md#fxy_gen" target="_blank">README.md</a> for a complete detail of the semantics of the parameters supported on the command line.
			<br/>
		</p>
		<h3>An example of using the program fxy_gen.py</h3>
		<p>
			Suppose you want to approximate in the rectagle $[-5.0,5.0]\times[-5.0,5.0]$ the function $$\sin \sqrt{x^2 + y^2}$$.
			Keeping in mind that <em>np</em> is the alias of NumPy library, the translation of this function in lambda body Python syntax is:
			<pre><code class="python">np.sin(np.sqrt(x**2 + y**2))</code></pre>
			To generate the training dataset, run the following command:
			<br/>
			<br/>
			<pre><code class="shell">$ python fxy_gen.py \
  --dsout mytrain.csv \
  --fxy "np.sin(np.sqrt(x**2 + y**2))" \
  --rxbegin -5.0 \
  --rxend 5.0 \
  --rybegin -5.0 \
  --ryend 5.0 \
  --rstep 0.075</code></pre>
			instead to generate the test dataset, run the following command:
			<br/>
			<br/>
			<pre><code class="shell">$ python fxy_gen.py \
  --dsout mytest.csv \
  --fxy "np.sin(np.sqrt(x**2 + y**2))" \
  --rxbegin -5.0 \
  --rxend 5.0 \
  --rybegin -5.0 \
  --ryend 5.0 \
  --rstep 0.275</code></pre>
			Note that the discretization step of the test dataset is larger than that of training and it is a normal fact
			because the training, to be accurate, it must be run on more data.
			Also note that it is appropriate for the discretization step of the test dataset is <u>not</u> a multiple of the training one
			in order to ensure that the test dataset contains most of the data that is not present in training dataset, and this makes prediction more interesting.
		</p>

		<h2>MLP architecture definition + Training</h2>
		<p>
			Goal of the <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/two-variables-function-fitting/fxy_fit.py" target="_blank"><code>fxy_fit.py</code></a> Python program
			is to dynamically create a MLP and perform its training according to the passed parameters through the command line.
			To get the program usage you can run this following command:
			<pre><code class="shell">$ python fxy_fit.py --help</code></pre>
			and the output got is:
			<br/>
			<br/>
			<pre><code class="shell">usage: fxy_fit.py [-h]
--trainds TRAIN_DATASET_FILENAME
--modelout MODEL_PATH
[--epochs EPOCHS]
[--batch_size BATCH_SIZE]
[--hlayers HIDDEN_LAYERS_LAYOUT [HIDDEN_LAYERS_LAYOUT ...]]
[--hactivations ACTIVATION_FUNCTIONS [ACTIVATION_FUNCTIONS ...]]
[--optimizer OPTIMIZER]
[--loss LOSS]</code></pre>
			Please read the file <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/two-variables-function-fitting/README.md#fxy_fit" target="_blank">README.md</a> for a complete detail of the semantics of the parameters supported on the command line.
			<br/>
		</p>
		<h3>An example of using the program fxy_fit.py</h3>
		<p>
			Suppose you have a training dataset available (for example generated through <code>fxy_gen.py</code> program as shown in the previous paragraph)
			and you want the MLP to have two hidden layers with both 100 neurons and that you want to use the relu activation function output from all two layers;
			moreover you want to perform 10 training epochs with a 50 items batch size using the SGD optimizator algorithm with default learning rate,
			momentum equal to 0.9, decay equal to 10<sup>-6</sup> and nesterov flag set to true and loss function equal to MeanSquaredError.
			To put all this into action, run the following command:
			<br/>
			<br/>
			<pre><code class="shell">$ python fxy_fit.py \
  --trainds mytrain.csv \
  --modelout mymodel \
  --hlayers 100 100 \
  --hactivations relu relu \
  --epochs 10 \
  --batch_size 50 \
  --optimizer 'SGD(decay=1e-6, momentum=0.9, nesterov=True)' \
  --loss 'MeanSquaredError()'</code></pre>
			at the end of which the folder <code>mymodel</code> will contain the MLP model trained on <code>mytrain.csv</code> dataset according to the parameters passed on the command line.
		</p>

		<h2>Prediction</h2>
		<p>
			Goal of the <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/two-variables-function-fitting/fxy_predict.py" target="_blank"><code>fxy_predict.py</code></a> Python program
			is to apply the MLP model generated through <code>fxy_fit.py</code> to an input dataset (for example the test dataset generated through <code>fxy_gen.py</code> program as shown in a previous paragraph);
			the execution of the program produces in output a csv file with three columns (without header): the first two columns contains the values of indepedent variable $x$ and $y$ taken from test dataset
			and the third column contains the predicted values of dependent variable, ie the values of the prediction correspondent to values of $x$ and $y$ of first two columns.
			<br/>
			To get the program usage you can run this following command:
			<pre><code class="shell">$ python fxy_predict.py --help</code></pre>
			and the output got is:
			<br/>
			<br/>
			<pre><code class="shell">usage: fxy_predict.py [-h]
--model MODEL_PATH
--ds DATASET_FILENAME
--predictionout PREDICTION_DATA_FILENAME</code></pre>
			Please read the file <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/two-variables-function-fitting/README.md#fxy_predict" target="_blank">README.md</a> for a complete detail of the semantics of the parameters supported on the command line.
			<br/>
		</p>
		<h3>An example of using the program fxy_predict.py</h3>
		<p>
			Suppose you have the test dataset <code>mytest.csv</code> available (for example generated through <code>fxy_gen.py</code> program as shown in a previous paragraph)
			and the trained model of MLP in the folder <code>mymodel</code> (generated through <code>fxy_fit.py</code> program as shown in the example of previous paragraph); run the following command:
			<br/>
			<br/>
			<pre><code class="shell">$ python fxy_predict.py \
  --model mymodel \
  --ds mytest.csv \
  --predictionout myprediction.csv
</code></pre>
			at the end of which the file <code>myprediction.csv</code> will contain the fitting of the initial function.
		</p>

		<h2>Visualization of the result</h2>
		<p>
			Goal of the <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/two-variables-function-fitting/fxy_plot.py" target="_blank"><code>fxy_plot.py</code></a> Python program
			is to visualize the prediction curve superimposed on initial dataset curve (test or training, as you prefer) and it allows the visual comparison of the two curves.
			<br/>
			To get the program usage you can run this following command:
			<pre><code class="shell">$ python fxy_plot.py --help</code></pre>
			and the output got is:
			<br/>
			<br/>
			<pre><code class="shell">usage: fxy_plot.py [-h]
--ds DATASET_FILENAME
--prediction PREDICTION_DATA_FILENAME
[--savefig SAVE_FIGURE_FILENAME]</code></pre>
			Please read the file <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/two-variables-function-fitting/README.md#fxy_plot" target="_blank">README.md</a> for a complete detail of the semantics of the parameters supported on the command line.
			<br/>
		</p>
		<h3>An example of using the program fxy_plot.py</h3>
		<p>
			Having the test dataset <code>mytest.csv</code> available (for example generated through <code>fxy_gen.py</code> program as shown in a previous paragraph)
			and the prediction csv file (generated through <code>fxy_predict.py</code> program as shown in the previous paragraph), to generate the two xy-scatter charts, execute the following command:
			<br/>
			<br/>
			<pre><code class="shell">$ python fxy_plot.py \
  --ds mytest.csv \
  --prediction myprediction.csv</code></pre>
			which shows the two curves neighboring: in blue the input dataset, in red the prediction one.
			<br/>
			<b>Note</b>: Given the stochastic nature of the training phase, your specific results may vary. Consider running the example a few times.
		</p>
		<div class="betweentextlines"><img src="../../posts/neural-networks/two-variables-real-function-fitting-with-tensorflow/nn-2vrffwtf-example02.png" /></div>
		<div class="photocaption">Chart generated by the program <code>fxy_plot.py</code> that shows the fitting of the function $f(x)=\frac{\sin 2x}{e^\frac{x}{5}}$ made by the MLP.</div>
		<br/>

		<h2>Examples of cascade use of the four programs</h2>
		<p>
			In the folder <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/tree/master/two-variables-function-fitting/examples" target="_blank"><code>two-variables-function-fitting/examples</code></a>
			there are three shell scripts that show the use in cascade of the four programs in various combinations of parameters
			(MLP architecture, activation functions, optimization algorithm, loss function, training procedure parameters)
			To run the three examples, run the following commands:
<pre><code class="shell">$ cd two-variables-function-fitting/examples
$ sh example1.sh
$ sh example2.sh
$ sh example3.sh</code></pre>
			<b>Note</b>: Given the stochastic nature of these examples (relative to the training phase), your specific results may vary. Consider running the example a few times.
		</p>

		<h2 id="downloadcode">Download of the complete code</h2>
		<p>
			The complete code is available at <a target="_blank" href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/tree/master/two-variables-function-fitting">GitHub</a>.
			<br/>
			
			These materials are distributed under MIT license; feel free to use, share, fork and adapt these materials as you see fit.
			<br/>
			Also please feel free to submit pull-requests and bug-reports to this GitHub repository or contact me on my social media channels available on the top right corner of this page.
			<br/>

		</p>
	</section>


						</div>
				</div>
				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">
							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<div class="align-center"><img src="../../images/cm-logo-small.png" alt="Computational&nbsp;Mindset" /></div>
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="../../en/">Home</a></li>
										<li>
											<span class="opener">Neural&nbsp;Networks</span>
											<ul>
												<li><a href="../../en/neural-networks/">INDEX</a></li>
												<li><a href="../../en/neural-networks/differential-equations-and-neural-networks.html">Differential Equations and Neural Networks</a></li>
												<li><a href="../../en/neural-networks/univariate-equally-spaced-time-series-forecast-with-tensorflow.html">Forecast of a univariate equally spaced time series with TensorFlow</a></li>
												<li><a href="../../en/neural-networks/fitting-with-multi-layer-perceptrons-highly-configurable.html">Fitting with highly configurable multi layer perceptrons</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Quantum&nbsp;Computing</span>
											<ul>
												<li><a href="../../en/quantum-computing/">INDEX</a></li>
												<li><a href="../../en/quantum-computing/not-cnot-operators.html">NOT and C-NOT quantum gates</a></li>
												<li><a href="../../en/quantum-computing/random-number-generation.html">Random Numbers Generation</a></li>
												<li><a href="../../en/quantum-computing/hadamard-gate-cascade.html">Cascade Hadamard Gates</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Machine&nbsp;Learning</span>
											<ul>
												<li><a href="../../en/machine-learning/">INDEX</a></li>
												<li><a href="../../en/machine-learning/fitting-with-configurable-xgboost.html">Fitting functions with a configurable XGBoost regressor</a></li>
												<li><a href="../../en/machine-learning/fitting-with-configurable-svr.html">Fitting functions with a configurable Support Vector Regressor</a></li>
												<li><a href="../../en/machine-learning/polynomial-regression-with-accord-net.html">Polynomial regression with Accord.NET</a></li>
												<li><a href="../../en/machine-learning/smo-regression-with-puk-kernel-in-weka.html">SMO regression for SVM with PUK kernel in Weka</a></li>
												<li><a href="../../en/machine-learning/smo-forecast-with-poly-kernel-in-weka.html">SMO forecast for SVM with polynomial kernel in Weka</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Mathematics</span>
											<ul>
												<li><a href="../../en/mathematics/">INDEX</a></li>
												<li><a href="../../en/mathematics/integral-calculus-in-python.html">Integral Calculus in Python</a></li>
												<li><a href="../../en/mathematics/analyzer-of-a-constant-coefficient-linear-and-homogeneous-dynamical-system-on-plane.html">Analyzer of a constant coefficient linear and homogeneous dynamical system on plane</a></li>
												<li><a href="../../en/mathematics/analyzer-of-a-nonlinear-autonomous-dynamical-system-on-plane-by-hartman-grobman-theorem.html">Analyzer of a nonlinear autonomous dynamical system on the plane by Hartman-Grobman theorem</a></li>
												<li><a href="../../en/mathematics/experiments-with-sympy-to-solve-odes-1st-order.html">Experiments with SymPy to solve first-order ordinary differential equations</a></li>
												<li><a href="../../en/mathematics/method-solving-first-order-dde-using-lambert-w-function.html">A method to solve first-order time delayed differential equation using Lambert W function</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Datasets</span>
											<ul>
												<li><a href="../../en/datasets/">INDEX</a></li>
												<li><a href="../../en/datasets/functions-dataset.html">&apos;Functions&apos; dataset collection</a></li>
												<li><a href="../../en/datasets/time-series-dataset.html">&apos;Time&nbsp;Series&apos; dataset collection</a></li>
												<li><a href="../../en/datasets/synthetic-words-dataset.html">&apos;Synthetic Words&apos; dataset</a></li>
											</ul>
										</li>
										<li><a href="../../en/info.html">Info</a></li>
									</ul>
								</nav>

							<!-- Section -->
								<section>
                                    <div class="side-topics">
                                        <header class="align-center">
                                            <h2><a href="../../en/neural-networks/">Neural&nbsp;Networks</a></h2>
                                        </header>
                                        <article>
                                            <a href="../../en/neural-networks/" class="image"><span class="icon solid fa-sitemap"/></a>
                                        </article>
                                        <header class="align-center">
                                            <h2><a href="../../en/quantum-computing/">Quantum&nbsp;Computing</a></h2>
                                        </header>
                                        <article>
                                            <a href="../../en/quantum-computing/" class="image"><span class="icon solid fa-atom" /></a>
                                        </article>
                                    </div>
								</section>

							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">
										Design based on &apos;Editorial&apos; template (with customization) downloaded from <a href="https://html5up.net" target="_blank">HTML5 UP</a>.
										<br/>
										Click on links to see <a href="../../html5up-license/LICENSE.txt" target="_blank">LICENSE.txt</a> and <a href="../../html5up-license/README.txt" target="_blank">README.txt</a> files of &apos;Editorial&apos; template by HTML5 UP.
										<br>
										<br>
										&copy; <a href="../../en/info.html">Ettore Messina</a>. 
									</p>
								</footer>
						</div>
					</div>
			</div>

		<!-- Scripts -->
			<script src="../../assets/js/jquery.min.js"></script>
			<script src="../../assets/js/browser.min.js"></script>
			<script src="../../assets/js/breakpoints.min.js"></script>
			<script src="../../assets/js/util.js"></script>
			<script src="../../assets/js/main.js"></script>

			<style>
				a.cc-link
				{
				    border-bottom: none;
				}
				a.cc-link:hover
				{
					color: white !important;
				}
			</style>
	</body>
</html>

