  

<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head lang="en">
		<meta http-equiv="content-language" content="en">
		<meta name="author" content="Ettore Messina">	

		<style>
			#cookiescript_checkbox_input {
				-moz-appearance: checkbox;
				-webkit-appearance: checkbox;
				-ms-appearance: checkbox;
				appearance: checkbox;
				opacity: 1.0;
			}
			#cookiescript_checkbox_text {
				color: white;
			}
			#cookiescript_description a:hover {
				color: yellow !important;
			}
		</style>
		<script type="text/javascript" charset="UTF-8" src="https://cookie-script.com/s/19e1626ea9f21a6fcc285b559b5957e6.js"></script>


		<title>Fitting functions with PyCaret</title>
		<meta name="description" content="Fitting of functions with PyCaret" >
		<meta name="keywords" content="regression, pycaret, approximation, fit, fitting, function, dataset, machine learning" >
		<link rel="canonical" href="https://computationalmindset.com/en/machine-learning/fitting-functions-with-pycaret.html" />
		<link rel="alternate" hreflang="en" href="https://computationalmindset.com/en/machine-learning/fitting-functions-with-pycaret.html" />
		<link rel="alternate" hreflang="it" href="https://computationalmindset.com/it/machine-learning/approssimazione-di-funzioni-con-pycaret.html" />
		
    <!-- SCHEMA.ORG JSON-LD WEBSITE -->
    <script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "WebSite",
        "name": "Computational Mindset",
        "url": "https://computationalmindset.com/",
        "sameAs": ["https://www.facebook.com/ComputationalMindset/", "https://github.com/ettoremessina/"],
        "author":
        {
          "@type": "Person",
          "name": "Ettore Messina",
          "image": "https://computationalmindset.com/images/ettore-messina.jpg",
          "gender": "Male",          
          "sameAs": ["https://www.facebook.com/ettore.messina.73/", "https://www.instagram.com/etmessina/", "https://twitter.com/ettoremessina/", "https://twitter.com/Computational_M/", "https://github.com/ettoremessina/", "https://medium.com/@ettoremessina/", "https://www.linkedin.com/in/ettoremessina", "https://www.linkedin.com/company/computational-mindset", "https://ettoremessina.tech/"]
        }
    }
    </script>

		
    <script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BreadcrumbList",
        "itemListElement":
        [
		
          {
            "@type": "ListItem",
            "position": 1,
            "item":
            {
                "@id": "https://computationalmindset.com/it/",
                "name": "Mentalit&agrave; Computazionale"
            }
          },
		
          {
            "@type": "ListItem",
            "position": 2,
            "item":
            {
              "@id": "https://computationalmindset.com/it/machine-learning/",
              "name": "Machine Learning"
            }
          },
          {
            "@type": "ListItem",
            "position": 3,
            "item":
            {
              "@id": "https://computationalmindset.com/en/machine-learning/fitting-functions-with-pycaret.html",
              "name": "Fitting functions with PyCaret"
            }
		  }
		
        ]
    }
    </script>
		

		<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/railscasts.min.css">
		<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>
		
		<script>hljs.initHighlightingOnLoad();</script>
		<style>
			pre > code 
			{
				font-size: 1.2em;
			}
		</style>

		
		<script type="text/x-mathjax-config">
			MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
		</script>
		<script type="text/javascript"
			src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>

		<!-- OPEN GRAPH PROTOCOL --------------------------------------------------------------------->
		<meta property="og:url" content="https://computationalmindset.com/en/machine-learning/fitting-functions-with-pycaret.html" />
		<meta property="og:type" content="article" />
		<meta property="og:title" content="" />
		<meta property="og:description" content="" />
		<meta property="og:image" content="/social-previews/thumbnail24.jpg" />
		<!-- OPEN GRAPH PROTOCOL --------------------------------------------------------------------->


		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../../assets/css/main.css" />
		<link rel="shortcut icon" href="../../favicon.ico" type="image/x-icon" />
		<link rel="icon" href="../../favicon.ico" type="image/x-icon" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="../../en/info.html" class="logo"><strong>Computational&nbsp;Mindset</strong> by&nbsp;Ettore&nbsp;Messina</a>
									<div style="text-align:right">
										<a class="logo" href="../../en/">en</a>
										&nbsp;&nbsp;&nbsp;
										<a class="logo" href="../../it/">it</a>
									</div>
									<ul class="icons">
										<li><a href="https://github.com/ettoremessina/" class="icon brands fa-github" target="_blank"><span class="label">GitHub</span></a></li>
										<li><a href="https://www.linkedin.com/company/computational-mindset" class="icon brands fa-linkedin" target="_blank"><span class="label">LinkedIn</span></a></li>
										<li><a href="https://twitter.com/Computational_M/" class="icon brands fa-twitter" target="_blank"><span class="label">Twitter</span></a></li>
										<li><a href="https://www.facebook.com/ComputationalMindset/" class="icon brands fa-facebook-f" target="_blank"><span class="label">Facebook</span></a></li>
										<li><a href="https://www.youtube.com/c/ComputationalMindset" class="icon brands fa-youtube" target="_blank"><span class="label">YouTube</span></a></li>
										<li><a href="https://linktr.ee/ComputationalMindset/" class="fas fa-link" style="color: grey;" target="_blank"><span class="label"></span></a></li>
										<li><a href="https://ettoremessina.tech/" class="icon brands fa-wordpress" target="_blank"><span class="label">WordPress</span></a></li>
									</ul>
								</header>

<!-- Content -->
	<section>
		<header class="main">
			<h1>Fitting functions with PyCaret</h1>
		</header>

		<p>
			This post deals with the approximation of real mathematical functions to one or more real variables using <a href="https://pycaret.org/" target="_blank"><em>PyCaret</em></a>
			without writing code but only acting on the command line of Python scripts that implement the functionality of:
			<ul>
				<li>
					<a href="#training"><em>Configuration of general parameters of PyCaret regressor and training</em></a>
				</li>
				<li>
					<a href="#prediction"><em>Prediction and error calculation</em></a>
				</li>
			</ul>

			The code described by this post requires Python version 3 and uses the PyCaret library; it also requires the NumPy, Pandas, nad MatPlotLib libraries.<br/>
			To get the code please see the paragraph <a href="#downloadcode">Download of the complete code</a> at the end of this post.<br/>
			<br/>
			For the generation of synthetic training and test datasets, the following common tools (available in the repository) will be used:
			<ul>
				<li>
					<a target="_blank" href="../../en/machine-learning/common-tools-for-function-fitting.html#fx_gen"><code>fx_gen.py</code></a> for the real-valued scalar functions of one real-valued variable $f \colon [a,b] \to {\rm I\!R}$
				</li>
				<li>
					<a target="_blank" href="../../en/machine-learning/common-tools-for-function-fitting.html#fxy_gen"><code>fxy_gen.py</code></a> for the real-valued scalar functions of two real-valued variables $f(x,y) \colon [a,b] \times [c,d] \to {\rm I\!R}$
				</li>
			</ul>			
			Also for the visualization of the results, and precisely for the comparison of the test dataset with the prediction, the following common tools (always available in the repository) will be used:
			<ul>
				<li>
					<a target="_blank" href="../../en/machine-learning/common-tools-for-function-fitting.html#fx_scatter"><code>fx_scatter.py</code></a> for the real scalar generator functions of one real variable
				</li>
				<li>
					<a target="_blank" href="../../en/machine-learning/common-tools-for-function-fitting.html#fxy_scatter"><code>fxy_scatter.py</code></a> for the real scalar generator functions of two real variables
				</li>
			</ul>
		</p>

		<h2 id="training">Configuration of general parameters of PyCaret regressor and training</h2>
		<p>
			This chapter presents the program: <a target="_blank" href="https://github.com/ettoremessina/function-fitting/blob/master/pycaret/fit_func.py"><code>fit_func.py</code></a>
			that implements in sequence five calls to as many functions of the <em>PyCaret</em> library:
			<ul>
				<li>
					<a target="_blank" href="https://pycaret.readthedocs.io/en/latest/api/regression.html?highlight=regression%20setup#pycaret.regression.setup"><code>regression.setup</code></a>
					which initializes the training environment and creates the transformation pipeline.
				</li>
				<li>
					<a target="_blank" href="https://pycaret.readthedocs.io/en/latest/api/regression.html?highlight=regression%20compare_models#pycaret.regression.compare_models"><code>regression.compare_models</code></a>
					which trains and evaluates the performance of all available estimators in the model library using cross-validation.<br />
					<b>Note</b>: in general <code>compare_models</code> returns a grid of average scores from the various cross-validated estimators;
					the <code>fit_func.py</code> program will use the best performing estimator, namely the one in the first row of the grid.
				</li>
				<li>
					<a target="_blank" href="https://pycaret.readthedocs.io/en/latest/api/regression.html?highlight=regression%20tune_model#pycaret.regression.tune_model"><code>regression.tune_model</code></a>
					which tunes the hyperparameters of a given estimator; the <code>fit_func.py</code> program will apply <code>tune_model</code> to the best estimator found by <code>compare_models</code> in the previous step.
				</li>
				<li>
					<a target="_blank" href="https://pycaret.readthedocs.io/en/latest/api/regression.html?highlight=regression%20finalize_model#pycaret.regression.finalize_model"><code>regression.finalize_model</code></a>
					that trains a data estimator on the entire data set; the <code>fit_func.py</code> program will apply <code>finalize_model</code> to the estimator returned by <code>tune_model</code> in the previous step.
				</li>
				<li>
					<a target="_blank" href="https://pycaret.readthedocs.io/en/latest/api/regression.html?highlight=regression%20save_model#pycaret.regression.save_model"><code>regression.save_model</code></a>
					saves the transformation pipeline and the trained model object to a file in <em>pickle</em> format for later use by <code>predict_func.py</code>.
				</li>
			</ul>

			The purpose of this program is to execute the above sequence of commands to allow PyCaret
			to choose the best machine learning algorithm to perform regression to approximate functions
			without having to write code but acting only on the command line.<br />
			In fact through the <code>--setupparams</code> argument the user passes a series of hyperparameters to configure the regression of PyCaret
			and through the argument <code>--compareparams</code> instead the user passes a series of hyperparameters to the comparison between the algorithms made by PyCaret.
			Besides the hyperparameters of the underlying PyCaret library, the program supports its own arguments to allow the user to pass
			the training dataset and the file where to save the trained model.<br />
			<br />
			The program is of type <em>M.I.S.O.</em>, that is <em>Multiple Input Simple Output</em>:
			is designed to approximate a function of the form $f \colon \rm I\!R^n \to \rm I\!R$.<br />
			The format of the input dataset is in csv format (with header); one of these columns (indicated by a mandatory argument in the command line)
			is the target column (the one related to the dependent variable) while all other columns contain the values of the independent variables.
		</p>

		<h3 id="fit_func">Usage of the fit_func.py program</h3>
		<p>
			To get the program usage you can run this following command:
			<pre><code class="shell">$ python fit_func.py --help</code></pre>
			and the output got is:
			<br/>
			<br/>
			<pre><code class="shell">usage: fit_func.py [-h] [--version] --trainds TRAIN_DATASET_FILENAME
                   --targetcol TARGET_COLUMN --modelout MODEL_FILE
                   [--metric METRIC] [--setupparams SETUP_PARAMS]
                   [--compareparams COMPARE_PARAMS]

fit_func.py fits a multiple-input single-output function dataset using the
best regressor chosen by PyCaret

optional arguments:
  -h, --help            show this help message and exit
  --version             show program's version number and exit
  --trainds TRAIN_DATASET_FILENAME
                        Train dataset file (csv format)
  --targetcol TARGET_COLUMN
                        Target column name
  --modelout MODEL_FILE
                        Output model file
  --metric METRIC       metric to evaluate the best model
  --setupparams SETUP_PARAMS
                        Parameters of PyCaret regression.setup function
  --compareparams COMPARE_PARAMS
                        Parameters of PyCaret regression.compare_models
                        function</code></pre>
			Where:
			<ul>
				<li>
					<b>-h, --help</b>: shows the usage of the program and ends the execution.<br />
					<br />
				</li>
				<li>
					<b>--version</b>: shows the version of the program and ends the execution.<br />
					<br />
				</li>
				<li>
					<b>--trainds</b>: path (relative or absolute) of a csv file (with header) that contains the dataset to be used for the training;
					this file can be generated synthetically e.g. via the program <a target="_blank" href="../../en/machine-learning/common-tools-for-function-fitting.html#fx_gen"><code>fx_gen.py</code></a>.
					or be a dataset actually obtained by measuring a scalar and real phenomenon that depends on a single real-valued variable.<br />
					<br />
				</li>
				<li>
					<b>--targetcol</b>: name of the column representing the dependent variable.<br />
					<br />
				</li>
				<li>
					<b>--modelout</b>: path (relative or absolute) to a file where to save the trained model in <em>pickle</em> format.<br />
					<br />
				</li>
				<li>
					<b>--metric</b>: The metrics to be used in sorting the scoring grid.
					Allowed values are: MAE, MSE, RMSE, R2, RMSLE, MAPE; the default is R2.<br />
					<br />
				</li>
				<li>
					<b>--setupparams</b>:
						list of parameters to pass to the function <code>regression.setup</code> below;
						see documentation of <a target="_blank" href="https://pycaret.readthedocs.io/en/latest/api/regression.html?highlight=regression%20setup#pycaret.regression.setup"><code>regression.setup</code></a>.<br />
					<br />
				</li>
				<li>
					<b>--compareparams</b>:
						list of parameters to pass to the function <code>regression.compare_models</code> below;
						see documentation of <a target="_blank" href="https://pycaret.readthedocs.io/en/latest/api/regression.html?highlight=regression%20compare_models#pycaret.regression.compare_models"><code>regression.compare_models</code></a>
					<br />
				</li>
			</ul>
		</p>

		<h2 id="prediction">Prediction and error calculation</h2>
		<p>
			In this chapter the program <a href="https://github.com/ettoremessina/function-fitting/blob/master/pycaret/predict_func.py" target="_blank"><code>predict_func.py</code></a> is presented
			and which purpose is to make predictions on a test dataset applying it to a previously selected and trained model by PyCaret
			via the program <a target="_blank" href="https://github.com/ettoremessina/function-fitting/blob/master/pycaret/fit_func.py"><code>fit_func.py</code></a>
			always without having to write code but only through the command line.<br />
			In fact, this program supports arguments through which the user passes the previously selected and trained model, the test dataset
			and the error measurements to be calculated between the predictions and the true values.<br />
			The format of the incoming test datasets is identical to that of the training programs mentioned above; obviously here the target column
			(that of dependent variables) is only used to compare the predicted values with the true values by calculating passed error measurements.<br />
		</p>

		<h3 id="predict_func_miso">Usage of the predict_func.py program</h3>
		<p>
			To get the program usage you can run this following command:
			<pre><code class="shell">$ python predict_func.py --help</code></pre>
			and the output got is:
			<br/>
			<br/>
			<pre><code class="shell">usage: predict_func.py [-h] [--version] --model MODEL_FILE --ds DF_PREDICTION
                       --targetcol TARGET_COLUMN --predictionout
                       PREDICTION_DATA_FILE
                       [--measures MEASURES [MEASURES ...]]

predict_func.py makes prediction of the values of a multiple-input single-
output function with the best pretrained regressor chosen by PyCaret

optional arguments:
  -h, --help            show this help message and exit
  --version             show program's version number and exit
  --model MODEL_FILE    model file
  --ds DF_PREDICTION    dataset file (csv format)
  --targetcol TARGET_COLUMN
                        Target column name
  --predictionout PREDICTION_DATA_FILE
                        prediction data file (csv format)
  --measures MEASURES [MEASURES ...]
                        List of built-in sklearn regression measures to
                        compare prediction with input dataset</code></pre>
			Where:
			<ul>
				<li>
					<b>-h, --help</b>: shows the usage of the program and ends the execution.<br />
					<br />
				</li>
				<li>
					<b>--version</b>: shows the version of the program and ends the execution.<br />
					<br />
				</li>
				<li>
					<b>--model</b>: path (relative or absolute) to the file in <em>pickle</em> format of the model selected and trained by PyCaret and generated by the program mentioned above.<br />
					<br />
				</li>
				<li>
					<b>--ds</b>: path (relative or absolute) of the csv file (with header) that contains the input dataset on which to calculate the prediction.<br />
					<br />
				</li>
				<li>
					<b>--targetcol</b>: name of the column representing the dependent variable.<br />
					<br />
				</li>
				<li>
					<b>--predictionout</b>: path (relative or absolute) of the csv file to generate that will contain the prediction, that is the approximation of the function applied to the input dataset.<br />
					<br />
				</li>
				<li>
					<b>--measures</b>: list of measurements to be calculated by comparing the true values of the input dataset and the predicted output values;
					the list of supported metrics is defined in <a target="_blank" href="https://scikit-learn.org/stable/modules/classes.html#regression-metrics">SciKit Learn Regression Metrics</a>.<br />
					<br />
				</li>
			</ul>
		</p>

		<h2>Examples of approximation of real-valued scalar function of a real-valued variable</h2>

		<h3>Example #1</h3>
		<p>
			Suppose you want to approximate the function $$f(x)=\frac {1}{2} x^3 - 2 x^2 - 3 x - 1$$ in the range $[-10,10]$.
			The translation of this function in lambda body Python syntax is:
			<pre><code class="python">0.5*x**3 - 2*x**2 - 3*x - 1</code></pre>
			To generate the training dataset, by the <a href="https://github.com/ettoremessina/function-fitting/blob/master/one-variable-function/common/fx_gen.py" target="_blank"><code>fx_gen.py</code></a> program,
			run the following command:
			<br/>
			<br/>
			<pre><code class="shell">$ python fx_gen.py \
  --dsout mytrain.csv \
  --funcx "0.5*x**3 - 2*x**2 - 3*x - 1" \
  --xbegin -10.0 \
  --xend 10.0 \
  --xstep 0.01</code></pre>
			instead to generate the test dataset, run the following command:
			<br/>
			<br/>
			<pre><code class="shell">$ python fx_gen.py \
  --dsout mytest.csv \
  --funcx "0.5*x**3 - 2*x**2 - 3*x - 1" \
  --xbegin -10.0 \
  --xend 10.0 \
  --xstep 0.0475</code></pre>
			Note that the discretization step of the test dataset is larger than that of training and it is a normal fact
			because the training, to be accurate, it must be run on more data.
			Also note that it is appropriate for the discretization step of the test dataset is <u>not</u> a multiple of the training one
			in order to ensure that the test dataset contains most of the data that is not present in training dataset, and this makes prediction more interesting.
			<br />
			To this we intend to make a regression by <a href="https://github.com/ettoremessina/function-fitting/blob/master/pycaret/fit_func.py" target="_blank"><code>fit_func.py</code></a> program
			passing to the underlying regressor the following arguments: 'train_size': 0.8, 'session_id': 987654321, 'log_experiment': True, 'experiment_name': 'example1_pycaret';
			then run the following command:
			<br/>
			<br/>
			<pre><code class="shell">$ python fit_func.py \
  --trainds mytrain.csv \
  --targetcol y \
  --metric MAE \
  --modelout mymodel.pickle \
  --setupparams "'train_size': 0.8, 'session_id': 987654321,
    'log_experiment': True, 'experiment_name': 'example1_pycaret'"</code></pre>
			and at the end of the execution the program shows the best regression algorithm selected by PyCaret, which is in this experiment <em>ExtraTreesRegressor</em>
			and saves the file mymodel.pickle which contains the model of the selected, configured and trained regressor.<br />
			<br />
			Now we intend to perform the prediction and calculation of the error using the measurements <em>mean_absolute_error</em> and <em>mean_squared_error</em>
			by the <a href="https://github.com/ettoremessina/function-fitting/blob/master/pycaret/predict_func.py" target="_blank"><code>predict_func.py</code></a> program;
			then execute the following command:
			<br/>
			<br/>
			<pre><code class="shell">$ python predict_func.py \
  --model mymodel.pickle \
  --ds mytest.csv \
  --targetcol y \
  --predictionout mypred.csv \
  --measures mean_absolute_error mean_squared_error</code></pre>
  			and at the end of the execution the saved mypred.csv file contains the prediction performed by applying the model on the test data;
			the output of the program displays the error measures passed through the argument <code>--measures</code>
			and are very low: the first around $0.0161$ and the second around $0.002$.<br />
			Finally you want to make the comparative display of the test dataset with the prediction
			by the <a href="https://github.com/ettoremessina/function-fitting/blob/master/one-variable-function/common/fx_scatter.py" target="_blank"><code>fx_scatter.py</code></a> program;
			therefore run the following command:
			<br/>
			<br/>
			<pre><code class="shell">$ python fx_scatter.py \
  --ds mytest.csv \
  --prediction mypred.csv \
  --xlabel "x" \
  --ylabel "y=1/2 x^3 - 2x^2 - 3x - 1"</code></pre>
			that shows the dispersion graphs of the test dataset and the superimposed prediction: in blue the one of the test dataset, in red the prediction.
			The comparison of the two graphs clearly shows that the approximation has reached very high levels.<br />
		</p>
		<div class="betweentextlines"><img src="../../posts/machine-learning/fitting-functions-with-pycaret/ml-fitfnwcaret-example1.png" alt="Graph comparison between original function and the function approximated by the regressor selected and trained by PyCaret" /></div>
		<div class="photocaption">Figure with dispersion graphs showing the fitting in red overlay of the function<br />
		$f(x)=\frac {1}{2} x^3 - 2 x^2 - 3 x - 1$ and the original function below in blue.</div>
		<br />
		<br />
		<p>
			The shell script of this example (that show the use of these cascading programs) at the following url:<br />
			<a target="_blank" href="https://github.com/ettoremessina/function-fitting/tree/master/one-variable-function/pycaret/examples/example1.sh"><code>one-variable-function/pycaret/examples/example1.sh</code></a>.
		</p>

		<h3>Example #2</h3>
		<p>
			Suppose you want to approximate the function $$f(x)=\sin x $$ in the range $[-6,6]$.
			Keeping in mind that <em>np</em> is the alias of NumPy library, the translation of this function in lambda body Python syntax is:
			<pre><code class="python">np.sin(x)</code></pre>
			Executing the same steps as in the previous example, at the end the scatter plots of the test dataset and the prediction are shown superimposed: in blue that of the test dataset, in red the prediction.
			The comparison of the two graphs clearly shows that the approximation has reached very high levels.<br />
		</p>
		<div class="betweentextlines"><img src="../../posts/machine-learning/fitting-functions-with-pycaret/ml-fitfnwcaret-example2.png" alt="Graph comparison between original function and the function approximated by the regressor selected and trained by PyCaret" /></div>
		<div class="photocaption">Figure with dispersion graphs showing the fitting in red overlay of the function<br />
		$f(x)=\sin x $ and the original function below in blue.</div>
		<br />
		<br />
		<p>
			The shell script of this example (that show the use of these cascading programs) at the following url:<br />
			<a target="_blank" href="https://github.com/ettoremessina/function-fitting/tree/master/one-variable-function/pycaret/examples/example2.sh"><code>one-variable-function/pycaret/examples/example2.sh</code></a>.
		</p>

		<h3>Example #3</h3>
		<p>
			Suppose you want to approximate the function $$f(x)=e^{\sin x}$$ in the range $[-8,8]$.
			Keeping in mind that <em>np</em> is the alias of NumPy library, the translation of this function in lambda body Python syntax is:
			<pre><code class="python">np.exp(np.sin(x))</code></pre>
			Executing the same steps as in the previous example, at the end the scatter plots of the test dataset and the prediction are shown superimposed: in blue that of the test dataset, in red the prediction.
			The comparison of the two graphs clearly shows that the approximation has reached very high levels.<br />
		</p>
		<div class="betweentextlines"><img src="../../posts/machine-learning/fitting-functions-with-pycaret/ml-fitfnwcaret-example3.png" alt="Graph comparison between original function and the function approximated by the regressor selected and trained by PyCaret" /></div>
		<div class="photocaption">Figure with dispersion graphs showing the fitting in red overlay of the function<br />
		$f(x)=e^{\sin x}$ and the original function below in blue.</div>
		<br />
		<br />
		<p>
			The shell script of this example (that show the use of these cascading programs) at the following url:<br />
			<a target="_blank" href="https://github.com/ettoremessina/function-fitting/tree/master/one-variable-function/pycaret/examples/example3.sh"><code>one-variable-function/pycaret/examples/example3.sh</code></a>.
		</p>



		<h2>Examples of approximation of real-valued scalar function of two real-valued variables</h2>

		<h3>Example #1</h3>
		<p>
			Suppose you want to approximate the function $$f(x,y)=x^2 + y^2$$ in the set $[-5,5] \times [-5,5]$.
			The translation of this function in lambda body Python syntax is:
			<pre><code class="python">x**2 + y**2</code></pre>
			To generate the training dataset, by the <a href="https://github.com/ettoremessina/function-fitting/blob/master/two-variables-function/common/fxy_gen.py" target="_blank"><code>fxy_gen.py</code></a> program,
			run the following command:
			<br/>
			<br/>
			<pre><code class="shell">$ python fxy_gen.py \
  --dsout mytrain.csv \
  --funcxy "x**2 + y**2" \
  --xbegin -3.0 --xend 3.0 \
  --ybegin -3.0 --yend 3.0 \
  --xstep 0.05 --ystep 0.1</code></pre>
			instead to generate the test dataset, run the following command:
			<br/>
			<br/>
			<pre><code class="shell">$ python fyx_gen.py \
  --dsout mytest.csv \
  --funcxy "x**2 + y**2" \
  --xbegin -3.0 --xend 3.0 \
  --ybegin -3.0 --yend 3.0 \
  --xstep 0.0875 --ystep 0.5</code></pre>
			Note that the discretization step of the test dataset is larger than that of training and it is a normal fact
			because the training, to be accurate, it must be run on more data.
			Also note that it is appropriate for the discretization step of the test dataset is <u>not</u> a multiple of the training one
			in order to ensure that the test dataset contains most of the data that is not present in training dataset, and this makes prediction more interesting.
			<br />
			To this we intend to make a regression by <a href="https://github.com/ettoremessina/function-fitting/blob/master/pycaret/fit_func.py" target="_blank"><code>fit_func.py</code></a> program
			passing to the underlying regressor the following arguments: 'train_size': 0.8, 'session_id': 987654321, 'log_experiment': True, 'experiment_name': 'example1_pycaret';
			then run the following command:
			<br/>
			<br/>
			<pre><code class="shell">$ python fit_func.py \
  --trainds mytrain.csv \
  --targetcol z \
  --metric MAE \
  --modelout mymodel.pickle \
  --setupparams "'train_size': 0.8, 'session_id': 987654321,
    'log_experiment': True, 'experiment_name': 'example1_pycaret'"</code></pre>
			and at the end of the execution the program shows the best regression algorithm selected by PyCaret, which is in this experiment <em>ExtraTreesRegressor</em>
			and saves the file mymodel.pickle which contains the model of the selected, configured and trained regressor.<br />
			<br />
			Now we intend to perform the prediction and calculation of the error using the measurements <em>mean_absolute_error</em> and <em>mean_squared_error</em>
			by the <a href="https://github.com/ettoremessina/function-fitting/blob/master/pycaret/predict_func.py" target="_blank"><code>predict_func.py</code></a> program;
			then execute the following command:
			<br/>
			<br/>
			<pre><code class="shell">$ python predict_func.py \
  --model mymodel.pickle \
  --ds mytest.csv \
  --targetcol z \
  --predictionout mypred.csv \
  --measures mean_absolute_error mean_squared_error</code></pre>
  			and at the end of the execution the saved mypred.csv file contains the prediction performed by applying the model on the test data;
			the output of the program displays the error measures passed through the argument <code>--measures</code>
			and are very low: the first around $0.00389864$ and the second around $0.00004255$.<br />
			Finally you want to make the comparative display of the test dataset with the prediction
			by the <a href="https://github.com/ettoremessina/function-fitting/blob/master/two-variables-function/common/fxy_scatter.py" target="_blank"><code>fxy_scatter.py</code></a> program;
			therefore run the following command:
			<br/>
			<br/>
			<pre><code class="shell">$ python fxy_scatter.py \
  --ds mytest.csv \
  --prediction mypred.csv \
  --xlabel "x" \
  --ylabel "y" \
  --zlabel "z=x**2 + y**2"</code></pre>
			that shows alongside the dispersion graphs of the test dataset and the prediction: in blue the one of the test dataset, in red the prediction.
			The comparison of the two graphs clearly shows that the approximation has reached very high levels.<br />
		</p>
		<div class="betweentextlines"><img src="../../posts/machine-learning/fitting-functions-with-pycaret/ml-fitfnwcaret-example4.png" alt="Graph comparison between original function and the function approximated by the regressor selected and trained by PyCaret" /></div>
		<div class="photocaption">Figure with dispersion graphs showing the fitting in red overlay of the function<br />
		$f(x,y)=x^2 + y^2$ and alongside the original function in blue.</div>
		<br />
		<br />
		<p>
			The shell script of this example (that show the use of these cascading programs) at the following url:<br />
			<a target="_blank" href="https://github.com/ettoremessina/function-fitting/tree/master/two-variables-function/pycaret/examples/example1.sh"><code>two-variables-function/pycaret/examples/example1.sh</code></a>.
		</p>

		<h3>Example #2</h3>
		<p>
			Suppose you want to approximate the function $$f(x,y)=\sin \sqrt{x^2 + y^2}$$ in the range $[-5,5] \times [-5,5]$.
			Keeping in mind that <em>np</em> is the alias of NumPy library, the translation of this function in lambda body Python syntax is:
			<pre><code class="python">np.sin(np.sqrt(x**2 + y**2))</code></pre>
			Executing the same steps as in the previous example, at the end the scatter plots of the test dataset and the prediction are shown alongside: in blue that of the test dataset, in red the prediction.
			The comparison of the two graphs clearly shows that the approximation has reached very high levels.<br />
		</p>
		<div class="betweentextlines"><img src="../../posts/machine-learning/fitting-functions-with-pycaret/ml-fitfnwcaret-example5.png" alt="Graph comparison between original function and the function approximated by the regressor selected and trained by PyCaret" /></div>
		<div class="photocaption">Figure with dispersion graphs showing alongside the fitting in red overlay of the function<br />
		$f(x,y)=\sin \sqrt{x^2 + y^2}$ and the original function below in blue.</div>
		<br />
		<br />
		<p>
			The shell script of this example (that show the use of these cascading programs) at the following url:<br />
			<a target="_blank" href="https://github.com/ettoremessina/function-fitting/tree/master/two-variables-function/pycaret/examples/example2.sh"><code>two-variables-function/pycaret/examples/example2.sh</code></a>.
		</p>

        <h2>Citations</h2>
        <p>
            <pre><code class="text">@ManualPyCaret,
  author  = {Moez Ali},
  title   = {PyCaret: An open source, low-code machine learning library in Python},
  year    = {2020},
  month   = {April},
  note    = {PyCaret version 1.0.0},
  url     = {https://www.pycaret.org}
</code></pre>
        </p>

		<h2 id="downloadcode">Download of the complete code</h2>
		<p>
			The complete code is available at <a target="_blank" href="https://github.com/ettoremessina/function-fitting/tree/master/pycaret/">GitHub</a>.
			<br/>
			
			These materials are distributed under MIT license; feel free to use, share, fork and adapt these materials as you see fit.
			<br/>
			Also please feel free to submit pull-requests and bug-reports to this GitHub repository or contact me on my social media channels available on the top right corner of this page.
			<br/>

		</p>
	</section>

						</div>
				</div>
				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">
							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<div class="align-center"><img src="../../images/cm-logo-small.png" alt="Computational&nbsp;Mindset" /></div>
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="../../en/">Home</a></li>
										<li>
											<span class="opener">Neural&nbsp;Networks</span>
											<ul>
												<li><a href="../../en/neural-networks/">INDEX</a></li>
												<li><a href="../../en/neural-networks/pruning-of-neural-networks-with-tensorflow.html">Pruning of neural networks with TensorFlow</a></li>
												<li><a href="../../en/neural-networks/differential-equations-and-neural-networks.html">Differential Equations and Neural Networks</a></li>
												<li><a href="../../en/neural-networks/univariate-equally-spaced-time-series-forecast-with-tensorflow.html">Forecast of a univariate equally spaced time series with TensorFlow</a></li>
												<li><a href="../../en/neural-networks/fitting-with-multi-layer-perceptrons-highly-configurable.html">Fitting with highly configurable multi layer perceptrons</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Quantum&nbsp;Computing</span>
											<ul>
												<li><a href="../../en/quantum-computing/">INDEX</a></li>
												<li><a href="../../en/quantum-computing/not-cnot-operators.html">NOT and C-NOT quantum gates</a></li>
												<li><a href="../../en/quantum-computing/random-number-generation.html">Random Numbers Generation</a></li>
												<li><a href="../../en/quantum-computing/hadamard-gate-cascade.html">Cascade Hadamard Gates</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Machine&nbsp;Learning</span>
											<ul>
												<li><a href="../../en/machine-learning/">INDEX</a></li>
												<li><a href="../../en/machine-learning/common-tools-for-function-fitting.html">Common tools for function fitting</a></li>
												<li><a href="../../en/machine-learning/fitting-functions-with-pycaret.html">Fitting functions with PyCaret</a></li>
												<li><a href="../../en/machine-learning/fitting-with-configurable-xgboost.html">Fitting functions with a configurable XGBoost regressor</a></li>
												<li><a href="../../en/machine-learning/fitting-with-configurable-svr.html">Fitting functions with a configurable Support Vector Regressor</a></li>
												<li><a href="../../en/machine-learning/polynomial-regression-with-accord-net.html">Polynomial regression with Accord.NET</a></li>
												<li><a href="../../en/machine-learning/smo-regression-with-puk-kernel-in-weka.html">SMO regression for SVM with PUK kernel in Weka</a></li>
												<li><a href="../../en/machine-learning/smo-forecast-with-poly-kernel-in-weka.html">SMO forecast for SVM with polynomial kernel in Weka</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Mathematics</span>
											<ul>
												<li><a href="../../en/mathematics/">INDEX</a></li>
												<li><a href="../../en/mathematics/fourier-series-in-python.html">Fourier Series in Python</a></li>
												<li><a href="../../en/mathematics/solving-delay-differential-equations-in-python-using-numerical-methods.html">Solving delay differential equations using numerical methods in Python</a></li>
												<li><a href="../../en/mathematics/integral-calculus-in-python.html">Integral Calculus in Python</a></li>
												<li><a href="../../en/mathematics/analyzer-of-a-constant-coefficient-linear-and-homogeneous-dynamical-system-on-plane.html">Analyzer of a constant coefficient linear and homogeneous dynamical system on plane</a></li>
												<li><a href="../../en/mathematics/analyzer-of-a-nonlinear-autonomous-dynamical-system-on-plane-by-hartman-grobman-theorem.html">Analyzer of a nonlinear autonomous dynamical system on the plane by Hartman-Grobman theorem</a></li>
												<li><a href="../../en/mathematics/experiments-with-sympy-to-solve-odes-1st-order.html">Experiments with SymPy to solve first-order ordinary differential equations</a></li>
												<li><a href="../../en/mathematics/method-solving-first-order-dde-using-lambert-w-function.html">A method to solve first-order time delay differential equation using Lambert W function</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">High Performance</span>
											<ul>
												<li><a href="../../en/high-performance/">INDEX</a></li>
												<li><a href="https://ettoremessina.tech/2024/09/14/high-performance-computing-of-discrete-single-variable-derivative-with-cuda/" target="_blank">High-Performance Computing of Discrete Single Variable Derivative with CUDA</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Datasets</span>
											<ul>
												<li><a href="../../en/datasets/">INDEX</a></li>
												<li><a href="../../en/datasets/functions-dataset.html">&apos;Functions&apos; dataset collection</a></li>
												<li><a href="../../en/datasets/time-series-dataset.html">&apos;Time&nbsp;Series&apos; dataset collection</a></li>
												<li><a href="../../en/datasets/synthetic-words-dataset.html">&apos;Synthetic Words&apos; dataset</a></li>
											</ul>
										</li>
										<li><a href="../../en/info.html">Info</a></li>
									</ul>
								</nav>

							<!-- Section -->
								<section>
                                    <div class="side-topics">
                                        <header class="align-center">
                                            <h2><a href="../../en/neural-networks/">Neural&nbsp;Networks</a></h2>
                                        </header>
                                        <article>
                                            <a href="../../en/neural-networks/" class="image"><span class="icon solid fa-sitemap"/></a>
                                        </article>
                                        <header class="align-center">
                                            <h2><a href="../../en/quantum-computing/">Quantum&nbsp;Computing</a></h2>
                                        </header>
                                        <article>
                                            <a href="../../en/quantum-computing/" class="image"><span class="icon solid fa-atom" /></a>
                                        </article>
                                    </div>
								</section>

							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">
										Design based on &apos;Editorial&apos; template (with customization) downloaded from <a href="https://html5up.net" target="_blank">HTML5 UP</a>.
										<br/>
										Click on links to see <a href="../../html5up-license/LICENSE.txt" target="_blank">LICENSE.txt</a> and <a href="../../html5up-license/README.txt" target="_blank">README.txt</a> files of &apos;Editorial&apos; template by HTML5 UP.
										<br>
										<br>
										&copy; <a href="../../en/info.html">Ettore Messina</a>. 
									</p>
								</footer>
						</div>
					</div>
			</div>

		<!-- Scripts -->
			<script src="../../assets/js/jquery.min.js"></script>
			<script src="../../assets/js/browser.min.js"></script>
			<script src="../../assets/js/breakpoints.min.js"></script>
			<script src="../../assets/js/util.js"></script>
			<script src="../../assets/js/main.js"></script>

			<style>
				a.cc-link
				{
				    border-bottom: none;
				}
				a.cc-link:hover
				{
					color: white !important;
				}
			</style>
	</body>
</html>

