
<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html lang="it">
	<head>
		<meta http-equiv="content-language" content="it">
		<meta name="author" content="Ettore Messina">

		<style>
			#cookiescript_checkbox_input {
				-moz-appearance: checkbox;
				-webkit-appearance: checkbox;
				-ms-appearance: checkbox;
				appearance: checkbox;
				opacity: 1.0;
			}
			#cookiescript_checkbox_text {
				color: white;
			}
			#cookiescript_description a:hover {
				color: yellow !important;
			}
		</style>
		<script type="text/javascript" charset="UTF-8" src="https://cookie-script.com/s/19e1626ea9f21a6fcc285b559b5957e6.js"></script>
		<script type="text/plain" data-cookiescript="accepted" data-cookiecategory="performance" src="https://www.googletagmanager.com/gtag/js?id=UA-149444322-1"></script>
		<script type="text/plain" data-cookiescript="accepted" data-cookiecategory="performance">
			window.dataLayer = window.dataLayer || [];
			function gtag(){dataLayer.push(arguments);}
			gtag('js', new Date());
			gtag('config', 'UA-149444322-1', { 'anonymize_ip': true });
		</script>


		<title>Regressione polinomiale con Accord.NET</title>
		<meta name="description" content="Approssimazione di una funzione reale di una variable utilizzando la regressione polinomiale implementata dal framework Accord.NET per .NET Core" >
		<meta name="keywords" content="regressione, polonomiale, approssimazione, funzione, dataset, errore quadratico minimo, machine learning, accord.net, c#, .net core" >
		<link rel="canonical" href="https://computationalmindset.com/it/machine-learning/regressione-polinomiale-con-accord-net.html" />
		<link rel="alternate" hreflang="en" href="https://computationalmindset.com/en/machine-learning/polynomial-regression-with-accord-net.html" />
		<link rel="alternate" hreflang="it" href="https://computationalmindset.com/it/machine-learning/regressione-polinomiale-con-accord-net.html" />
		
    <!-- SCHEMA.ORG JSON-LD WEBSITE -->
    <script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "WebSite",
        "name": "Computational Mindset",
        "url": "https://computationalmindset.com/",
        "sameAs": ["https://www.facebook.com/ComputationalMindset/", "https://www.facebook.com/MentalitaComputazionale/", "https://github.com/ettoremessina/"],
        "author":
        {
          "@type": "Person",
          "name": "Ettore Messina",
          "image": "https://computationalmindset.com/images/ettore-messina.jpg",
          "gender": "Male",          
          "sameAs": ["https://www.facebook.com/ettore.messina.73/", "https://www.instagram.com/etmessina/", "https://twitter.com/ettoremessina/", "https://github.com/ettoremessina/"]
        }
    }
    </script>

		
    <script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BreadcrumbList",
        "itemListElement":
        [
		
          {
            "@type": "ListItem",
            "position": 1,
            "item":
            {
                "@id": "https://computationalmindset.com/it/",
                "name": "Mentalit&agrave; Computazionale"
            }
          },
		
          {
            "@type": "ListItem",
            "position": 2,
            "item":
            {
              "@id": "https://computationalmindset.com/it/machine-learning/",
              "name": "Machine Learning"
            }
          },

          {
            "@type": "ListItem",
            "position": 3,
            "item":
            {
              "@id": "https://computationalmindset.com/it/machine-learning/regressione-polinomiale-con-accord-net.html",
              "name": "Regressione polinomiale con Accord.NET"
            }
		  }
		
        ]
    }
    </script>
		

		<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/railscasts.min.css">
		<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>
		
		<script>hljs.initHighlightingOnLoad();</script>
		<style>
			pre > code 
			{
				font-size: 1.2em;
			}
		</style>

		
		<script type="text/javascript" src="https://latex.codecogs.com/latexit.js"></script>
		<script type="text/x-mathjax-config">
			MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
		</script>
		<script type="text/javascript"
			src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>



		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../../assets/css/main.css" />
		<link rel="shortcut icon" href="../../favicon.ico" type="image/x-icon" />
		<link rel="icon" href="../../favicon.ico" type="image/x-icon" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="../../it/info.html" class="logo"><strong>Mentalit&agrave;&nbsp;Computazionale</strong> di&nbsp;Ettore&nbsp;Messina</a>
									<div style="text-align:right">
										<a class="logo" href="../../en/">en</a>
										&nbsp;&nbsp;&nbsp;
										<a class="logo" href="../../it/">it</a>
									</div>
									<ul class="icons">
										<li><a href="https://github.com/ettoremessina/" class="icon brands fa-github" target="_blank"><span class="label">GitHub</span></a></li>
										<li><a href="https://twitter.com/ettoremessina/" class="icon brands fa-twitter" target="_blank"><span class="label">Twitter</span></a></li>
										<li><a href="https://www.facebook.com/MentalitaComputazionale/" class="icon brands fa-facebook-f" target="_blank"><span class="label">Facebook</span></a></li>
										<li><a href="https://www.instagram.com/etmessina/" class="icon brands fa-instagram" target="_blank"><span class="label">Instagram</span></a></li>
										<li><a href="https://www.linkedin.com/in/ettoremessina/" class="icon brands fa-linkedin" target="_blank"><span class="label">LinkedIn</span></a></li>
										<li><a href="https://t.me/ettoremessina/" class="icon brands fa-telegram" target="_blank"><span class="label">Skype</span></a></li>
										<li><a href="https://medium.com/@ettoremessina/" class="icon brands fa-medium-m" target="_blank"><span class="label">Medium</span></a></li>
										<li><a href="skype:ettore-messina?chat" class="icon brands fa-skype" target="_blank"> <span class="label">Skype</span></a></li>
									</ul>
								</header>

<!-- Content -->
	<section>
		<header class="main">
			<h1>Regressione polinomiale con Accord.NET</h1>
		</header>

		<p>
			Questo post mostra un uso della classe <em>PolynomialRegression</em> del framework <em>Accord.NET</em>
			con l&apos;obiettivo di dimostrare che la regressione polinomiale classica del machine learning pu&ograve; raggiungere interessanti livelli di accuratezza con tempi di learning estremamente brevi.<br />
			Anche se le reti neurali di tipo MLP (Multi Layer Perceptron) possono essere considerate degli approssimatori universali di funzioni (si veda <a href="../../it/reti-neurali/approssimazione-con-percettroni-multistrato-altamente-configurabili.html">Approssimazione con percettroni multistrato altamente configurabili</a> su questo sito web),
			per alcune tipologie di dataset, un classico algoritmo supervisionato di regressione di machine learning, come quello di regressione polinomiale di cui si tratta qui, pu&ograve; arrivare a livelli di accuratezza accettabili
			e con un costo computazionale decisamente pi&ugrave; basso rispetto a quello di un MLP.<br />
			<br />
			Nel mondo reale i dataset preesistono alla fase di apprendimento, infatti questi vengono ottenuti estraendo dati da database di produzione o file Excel, dall&apos;output di strumenti di misura, dai data-logger collegati a sensori elettronici e cos&igrave; via,
			e quindi adoperati per le fasi di learning successive;
			ma poich&eacute; qui il focus &egrave; l&apos;approssimazione polinomiale in s&eacute; e non l&apos;approssimazione di un fenomeno reale, i dataset utilizzati in questo post saranno generati sinteticamente:
			questo ha il vantaggio di poter stressare l&apos;algoritmo e vedere per quali tipologie di dataset l&apos;algoritmo ha accuratezza accettabile e per quali invece l&apos;algoritmo fatica. 
		</p>

		<h2>Implementazione</h2>
		<p>
			Il codice descritto da questo post &egrave; scritto il C#, richiede <a href="https://dotnet.microsoft.com/" target="_blank">Microsoft .NET Core</a> 3.1 e il framework <a href="http://accord-framework.net/" target="_blank">Accord.NET</a> 3.8.0.<br/>
			Per ottenere il codice si veda il paragrafo <a href='#downloadcode'>Download del codice completo</a> in fondo a questo post.<br/>
			La classe pi&ugrave; importante del progetto &egrave; la classe <a href="https://github.com/ettoremessina/accord-net-experiments/blob/master/Prototypes/CSharp/Regressors/Wrappers/PolynomialLeastSquares1to1Regressor.cs" target="_blank"><code>PolynomialLeastSquares1to1Regressor</code></a> che &egrave; un wrapper della classe
			<a href="http://accord-framework.net/docs/html/T_Accord_Statistics_Models_Regression_Linear_PolynomialRegression.htm" target="blank"><code>PolynomialRegression</code></a> di Accord.NET.<br/>
			<pre><code class="cs">using System.Globalization;
using System.Collections.Generic;
using System.Linq;
using Accord.Statistics.Models.Regression.Linear;
using Accord.Math.Optimization.Losses;
using Regressors.Entities;
using Regressors.Exceptions;

namespace Regressors.Wrappers
{
    public class PolynomialLeastSquares1to1Regressor
    {
        private int _degree;
        private bool _isRobust;
        private PolynomialRegression _polynomialRegression;

        public PolynomialLeastSquares1to1Regressor(int degree, bool isRobust = false)
        {
            _degree = degree;
            _isRobust = isRobust;
        }

        public double[] Weights
        {
            get
            {
                AssertAlreadyLearned();
                return _polynomialRegression.Weights;
            }
        }

        public double Intercept
        {
            get
            {
                AssertAlreadyLearned();
                return _polynomialRegression.Intercept;
            }
        }
        private void AssertAlreadyLearned()
        {
            if (_polynomialRegression == null)
                throw new NotTrainedException();
        }

        public string StringfyLearnedPolynomial(string format = "e")
        {
            if (_polynomialRegression == null)
                return string.Empty;
            
            return _polynomialRegression.ToString(format, CultureInfo.InvariantCulture);
        }

        public void Learn(IList&lt;XtoY&gt; dsLearn)
        {            
            double [] inputs = dsLearn.Select(i =&gt; i.X).ToArray();
            double [] outputs = dsLearn.Select(i =&gt; i.Y).ToArray();
            var pls = new PolynomialLeastSquares() { Degree = _degree, IsRobust = _isRobust };
            _polynomialRegression = pls.Learn(inputs, outputs);
        }

        public IEnumerable&lt;XtoY&gt; Predict(IEnumerable&lt;double&gt; xvalues)
        {
            AssertAlreadyLearned();

            double []xvaluesArray = xvalues.ToArray();
            double [] yvaluesArray = _polynomialRegression.Transform(xvaluesArray);
            for(int i = 0; i &lt; xvaluesArray.Length; ++i)
            {
                yield return new XtoY() {X = xvaluesArray[i], Y = yvaluesArray[i]};
            }
        }

        public static double ComputeError(IEnumerable&lt;XtoY&gt; ds, IEnumerable&lt;XtoY&gt; predicted)
        {
            double [] outputs = ds.Select(i =&gt; i.Y).ToArray();
            double [] preds = predicted.Select(i =&gt; i.Y).ToArray();
            double error = new SquareLoss(outputs).Loss(preds);
            return error;
        }
    }
}
</code></pre>
		</p>

		<h2>Esecuzione del codice</h2>
		<p>
			Su un sistema Linux, Mac o Windows ove .NET Core 3.1 e git client siano già installati, per scaricare il sorgente e mandare in esecuzione il programma, eseguire i seguenti comandi:
<pre><code class="shell">git clone https://github.com/ettoremessina/accord-net-experiments
cd accord-net-experiments/Prototypes/CSharp/Regressors
dotnet build
dotnet run</code></pre>
			La prima volta il comando di build potrebbe impiegare qualche secondo di tempo per effettuale il download di alcuni pacchetti di Accord.NET da NuGet; per rieseguire il programma dalla seconda volta in poi
			&egrave; sufficiente eseguire:<br /><br />
<pre><code class="shell">dotnet run</code></pre>
			Dopo ogni esecuzione nella cartella <code>out</code> vengono create nove cartelle, ciascuna corrispondente a un caso di test built-in (si veda la classe <code>PolynomialLeastSquares1to1RegressorTester</code>);
			ciascuna cartella contiene quattro file:
			<lu>
				<li>Il file <code>learnds.csv</code> che &egrave; il dataset di learning in formato csv con header.</li>
				<li>Il file <code>testds.csv</code> che &egrave; il dataset di test in formato csv con header.</li>
				<li>Il file <code>prediction.csv</code> che &egrave; il file della predizione  in formato csv con header.</li>
				<li>Lo script <code>plotgraph.m</code> per Octave.</li>
			</lu>
			<br />
			Il file <code>prediction.csv</code> è ottenuto applicando le $x$ del dataset di test al regressore che ha imparato la curva;
			si osservi che il passo di discretizzazione dei dataset di test <u>non</u> &egrave; un multiplo di quello di learning
			per garantire che il dataset di test contenga la maggior parte dei dati non presenti nel dataset di learning, e questo rende pi&ugrave; interessante la predizione.<br />
			Lo script <code>plotgraph.m</code>, se eseguito su Octave, produce un grafico con due curve: quella blu &egrave; il dataset di test, quella rossa &egrave; la predizione;
			i grafici mostrati qui di seguito sono stati generati eseguendo tali script. In alternativa si possono importare i file csv in Excel o altri software di foglio elettronico
			e generare i grafici tramite essi; infine &egrave; sempre possibile utilizzare servizi online di plotting di grafici a partire da file csv.<br />
			<br />
			L&apos;output del programma produce un blocco di output per ciascuno dei nove casi di test build-in;
			in particolare ogni blocco mostra il polinomio che approssima e l&apos;errore quadratico medio calcolato sul dataset di test. Qui in esempio del primo blocco di output:<br />
			<br />
			<pre><code class="cs">Started test #PLSR_01
Generating learning dataset
Generating test dataset
Training
Learned polynomial y(x) = 5.000000e-001x^3 + -2.000000e+000x^2 + -3.000000e+000x^1 + -1.000000e+000
Predicting
Error: 9.42921358148529E-24
Saving
Terminated test #PLSR_01
</code></pre>			
		</p>

		<h2>Caso di studio dell&apos;approssimazione polinomiale di una sinusoide</h2>
		<p>
			Dato il dataset sintetico generato con una sinusoide $f(x)=\sin x$ nell&apos;intervallo $[-2 \pi, 2 \pi]$, il primo tentativo di approssimazione &egrave; effettuato tentando con un polinomio di terzo grado;
			da questo grafico:
			<div class="betweentextlines"><img src="../../posts/machine-learning/accord-net-polynomial-regression/PLSR_02_degree3.png" /></div>
			<div class="photocaption">p(x) = -6.938440e-003x^3 + -1.123961e-004x^2 + 8.852045e-002x^1 + 8.879541e-004</div>
			<br />
			si evince palesemente che il risultato desiderato &egrave; assai lontato da quello desiderato e ha un errore quadratico medio di 0.35855442002271176.
		</p>
		<p>
			Ragionando empiricamente (attenzione: questo ragionamento non &egrave; appricabile in generale), osservando che la funzione da approssimare ha 2 minimi e 2 massimi relativi nell&apos;intervallo considerato
			ovverosia 5 tratti a direzione di crescita opposta, si osserva che serve almeno un polinomio di grado 5 per realizzare questi 5 tratti a direzione di crescita opposta.<br />
			In effetti, tentando ad approssimare con un polinomio di quinto grado le cose iniziano ad andare meglio:
			<div class="betweentextlines"><img src="../../posts/machine-learning/accord-net-polynomial-regression/PLSR_02_degree5.png" /></div>
			<div class="photocaption">p(x) = 1.481271e-003x^5 + 8.653159e-006x^4 + -7.195156e-002x^3 + -2.278718e-004x^2 + 6.388252e-001x^1 + 6.429388e-004</div>
			<br />
			e infatti l&apos;errore quadratico medio &egrave; di 0.047802033570042826.
		</p>
		<p>
			Alzando il grado del polinomio a 10, si nota che ci si avvicina in maniera interessante a una approssimazione molto accurata:
			<div class="betweentextlines"><img src="../../posts/machine-learning/accord-net-polynomial-regression/PLSR_02_degree10.png" /></div>
			<div class="photocaption">p(x) = 3.600998e-010x^10 + 1.030748e-006x^9 + -3.048007e-008x^8 + -1.432993e-004x^7 + 8.871355e-007x^6 + 7.507463e-003x^5 + -1.030648e-005x^4 + -1.614928e-001x^3 + 4.071080e-005x^2 + 9.908745e-001x^1 + -2.473974e-005</div>
			<br />
			e infatti l&apos;errore quadratico medio scende al valore molto basso di 1.730499971068361E-05.
		</p>

		<h2>Caso di studio dell&apos;approssimazione polinomiale di una funzione con una cuspide</h2>
		<p>
			Sia dato il dataset sintetico generato con la seguente funzione $f(x)=\sqrt{|x|}$ nell&apos;intervallo  $[-5, 5]$, che presenta una cuspide nell&apos;origine;
			la regressione polinomiale ha difficolt&agrave; ad approssimare la cuspide come si evince dal seguente grafico che mostra un polinomio di decimo grado
			che tenta di approssimare la funzione obiettivo:
			<div class="betweentextlines"><img src="../../posts/machine-learning/accord-net-polynomial-regression/PLSR_04_degree10.png" /></div>
			<div class="photocaption">p(x) = 3.937716e-006x^10 + -2.624859e-018x^9 + -2.677173e-004x^8 + 1.265696e-016x^7 + 6.737778e-003x^6 + -1.993373e-015x^5 + -7.799737e-002x^4 + 1.137932e-014x^3 + 4.557707e-001x^2 + -1.714000e-014x^1 + 5.263100e-001</div>
			<br />
			e palesemente si osserva che intorno alla cuspide l&apos;approssimazione non riesce; sull&apos;intero intervallo l&apos;errore quadratico medio &egrave; comunque interessante e vale 0.004819185301219476.
		</p>
		<p>
			Anche provando con un polinomio di grado 20:
			<div class="betweentextlines"><img src="../../posts/machine-learning/accord-net-polynomial-regression/PLSR_04_degree20.png" /></div>
			<div class="photocaption">p(x) = -1.484256e-010x^20 + 2.182564e-019x^19 + 1.919608e-008x^18 + -2.385482e-017x^17 + -1.064756e-006x^16 + 1.092940e-015x^15 + 3.310069e-005x^14 + -2.724916e-014x^13 + -6.325746e-004x^12 + 4.014962e-013x^11 + 7.671207e-003x^10 + -3.552878e-012x^9 + -5.887499e-002x^8 + 1.833481e-011x^7 + 2.773153e-001x^6 + -5.082524e-011x^5 + -7.577731e-001x^4 + 6.342430e-011x^3 + 1.180241e+000x^2 + -2.295607e-011x^1 + 3.844349e-00</div>
			<br />
			si migliora l&apos;approssimazione intorno alla cuspide ma non si riesce a risolverla; sull&apos;intero intervallo l&apos;errore quadratico medio &egrave; comunque notevolmente basso e vale 0.0014078917181083847.
		</p>

		<h2>Caso di studio dell&apos;approssimazione di un tratto di esponenziale</h2>
		<p>
			Anche se la funzione esponenziale non &egrave; approssimabile con un polinomio, contrariamente a quanto si possa pensare, su un tratto limitato l&apos;approssimazione raggiunge un grande livello di accuratezza.
			Data la funzione esponenziale $f(x)=e^x$ nell&apos;intervallo  $[-5, 5]$,
			la regressione polinomiale con un polinomio di quinto grado &egrave; gi&agrave; accettabile, con un errore quadratico medio pari a 0.9961909800481012, come mostra il grafico:
			<div class="betweentextlines"><img src="../../posts/machine-learning/accord-net-polynomial-regression/PLSR_03_degree5.png" /></div>
			<div class="photocaption">p(x) = 2.069063e-002x^5 + 1.196676e-001x^4 + 7.493153e-003x^3 + -2.482972e-001x^2 + 1.470547e+000x^1 + 1.955036e+000</div>
		</p>
		<p>
			Utilizzando un polinomio di decimo grado, l&apos;approssimazione diventa molto accurata, con un errore quadratico medio pari a 1.6342296507040001E-06:
			<div class="betweentextlines"><img src="../../posts/machine-learning/accord-net-polynomial-regression/PLSR_03_degree10.png" /></div>
			<div class="photocaption">p(x) = 4.697166e-007x^10 + 4.930956e-006x^9 + 1.916581e-005x^8 + 1.422306e-004x^7 + 1.460971e-003x^6 + 8.937498e-003x^5 + 4.125903e-002x^4 + 1.640806e-001x^3 + 5.008296e-001x^2 + 1.003040e+000x^1 + 9.997306e-001</div>			
		</p>
		
		<h2>Un caso di studio difficile: la sinusoide smorzata</h2>
		<p>
			La funzione $f(x)=\frac{\sin 2x}{e^\frac{x}{5}}$, che è una sorta di sinusoide smorzata, nell&apos;intervallo $[-20, 20]$ non sembra facile da approssimare per via dei tanti minimi e massimi locali presenti;
			per quanto detto sopra si tenta subito ad approssimare con un polinomio di alto grado, ad esempio un ventesimo grado; dal seguente grafico:
			<div class="betweentextlines"><img src="../../posts/machine-learning/accord-net-polynomial-regression/PLSR_09_degree20.png" /></div>
			<div class="photocaption">p(x) = 2.438374e-021x^20 + -1.303248e-019x^19 + -2.737692e-018x^18 + 2.182637e-016x^17 + 6.129847e-016x^16 + -1.513625e-013x^15 + 4.547323e-013x^14 + 5.628751e-011x^13 + -3.185157e-010x^12 + -1.215171e-008x^11 + 8.477405e-008x^10 + 1.541180e-006x^9 + -1.160371e-005x^8 + -1.108299e-004x^7 + 8.318767e-004x^6 + 4.124021e-003x^5 + -2.845069e-002x^4 + -6.550661e-002x^3 + 3.595534e-001x^2 + 2.775935e-001x^1 + -7.192461e-001</div>
			<br />
			si noti che il grado 20 non è sufficiente, e l&apos;errore quadratico medio &egrave; alto e uguale a 29.906606603488548.
		</p>
		<p>
			Utilizzando un polinomio di quarantesimo grado, l&apos;approssimazione diventa molto accurata, con un errore quadratico medio decisamente più basso pari a 0.03318409290980062:
			<div class="betweentextlines"><img src="../../posts/machine-learning/accord-net-polynomial-regression/PLSR_09_degree40.png" /></div>
			<div class="photocaption">p(x) = 2.620011e-041x^40 + -2.261159e-040x^39 + -1.064515e-037x^38 + 9.291263e-037x^37 + 2.000472e-034x^36 + -1.767156e-033x^35 + -2.306009e-031x^34 + 2.063269e-030x^33 + 1.823227e-028x^32 + -1.653595e-027x^31 + -1.047264e-025x^30 + 9.635843e-025x^29 + 4.515541e-023x^28 + -4.218466e-022x^27 + -1.489064e-020x^26 + 1.413717e-019x^25 + 3.790980e-018x^24 + -3.661427e-017x^23 + -7.468664e-016x^22 + 7.347405e-015x^21 + 1.134298e-013x^20 + -1.138497e-012x^19 + -1.314822e-011x^18 + 1.349687e-010x^17 + 1.143662e-009x^16 + -1.205220e-008x^15 + -7.274557e-008x^14 + 7.920025e-007x^13 + 3.256202e-006x^12 + -3.704228e-005x^11 + -9.671991e-005x^10 + 1.175149e-003x^9 + 1.729315e-003x^8 + -2.354541e-002x^7 + -1.527679e-002x^6 + 2.660934e-001x^5 + 3.057082e-002x^4 + -1.386296e+000x^3 + 1.984571e-001x^2 + 2.097913e+000x^1 + -2.557841e-001</div>			
		</p>

		<h2>Alternative</h2>
		<p>
			Per esempi di regressione di una funzione reale di una variable con SVM in Weka si veda <a href="../../it/machine-learning/regressione-smo-con-kernel-puk-in-weka.html">Regressione con SMO per SVM con kernel PUK in Weka</a>.<br />
			Per approfondire invece l&apos;approssimazione di una funzione reale di una variable con un MLP si veda <a href="../../it/reti-neurali/approssimazione-di-una-funzione-reale-di-una-variabile-con-tensorflow.html">Approssimazione di una funzione reale di una variabile con TensorFlow</a> e <a href="../../it/reti-neurali/approssimazione-di-una-funzione-reale-di-una-variabile-con-pytorch.html">Approssimazione di una funzione reale di una variabile con PyTorch</a>.<br />
		</p>

		<h2 id="downloadcode">Download del codice completo</h2>
		<p>
			Il codice completo &egrave; disponibile su <a target="_blank" href="https://github.com/ettoremessina/accord-net-experiments/tree/master/Prototypes/CSharp/Regressors">GitHub</a>.
			<br/>
			
			Questo materiale &egrave; distribuito su licenza MIT; sentiti libero di usare, condividere, &quot;forkare&quot; e adattare tale materiale come credi.
			<br/>
			Sentiti anche libero di pubblicare pull-request e bug-report su questo repository di GitHub oppure di contattarmi sui miei canali social disponibili nell&apos;angolo in alto a destra di questa pagina. 
			<br/>

		</p>
	</section>

						</div>
				</div>
				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">
							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="../../it/">Home</a></li>
										<li>
											<span class="opener">Reti&nbsp;Neurali</span>
											<ul>
												<li><a href="../../it/reti-neurali/">INDICE</a></li>
												<li><a href="../../it/reti-neurali/approssimazione-con-percettroni-multistrato-altamente-configurabili.html">Approssimazione con percettroni multistrato altamente configurabili</a></li>
												<li><a href="../../it/reti-neurali/approssimazione-di-una-funzione-reale-di-una-variabile-con-tensorflow.html">Approssimazione di una funzione reale di una variabile con TensorFlow</a></li>
												<li><a href="../../it/reti-neurali/approssimazione-di-una-funzione-reale-di-una-variabile-con-pytorch.html">Approssimazione di una funzione reale di una variabile con PyTorch</a></li>
												<li><a href="../../it/reti-neurali/approssimazione-di-una-curva-sul-piano-con-tensorflow.html">Approssimazione di una curva parametrica su un piano con TensorFlow</a></li>
												<li><a href="../../it/reti-neurali/approssimazione-di-una-curva-sul-piano-con-pytorch.html">Approssimazione di una curva parametrica su un piano con PyTorch</a></li>
												<li><a href="../../it/reti-neurali/approssimazione-di-una-curva-nello-spazio-con-tensorflow.html">Approssimazione di una curva parametrica nello spazio con TensorFlow</a></li>
												<li><a href="../../it/reti-neurali/approssimazione-di-una-curva-nello-spazio-con-pytorch.html">Approssimazione di una curva parametrica nello spazio con PyTorch</a></li>
												<li><a href="../../it/reti-neurali/approssimazione-di-una-funzione-reale-di-due-variabili-con-tensorflow.html">Approssimazione di una funzione reale di due variabili con TensorFlow</a></li>
												<li><a href="../../it/reti-neurali/approssimazione-di-una-funzione-reale-di-due-variabili-con-pytorch.html">Approssimazione di una funzione reale di due variabili con PyTorch</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Computazione&nbsp;Quantistica</span>
											<ul>
												<li><a href="../../it/computazione-quantistica/">INDICE</a></li>
												<li><a href="../../it/computazione-quantistica/porte-hadamard-in-cascata.html">Porte Hadamard in cascata</a></li>
												<li><a href="../../it/computazione-quantistica/generazione-numero-casuale.html">Generazione di un numero casuale</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Machine&nbsp;Learning</span>
											<ul>
												<li><a href="../../it/machine-learning/">INDICE</a></li>
												<li><a href="../../it/machine-learning/regressione-polinomiale-con-accord-net.html">Regressione polinomiale con Accord.NET</a></li>
												<li><a href="../../it/machine-learning/regressione-smo-con-kernel-puk-in-weka.html">Regressione con SMO per SVM con kernel PUK in Weka</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Dataset</span>
											<ul>
												<li><a href="../../it/datasets/">INDICE</a></li>
												<li><a href="../../it/datasets/synthetic-words-dataset.html">Dataset &apos;Synthetic Words&apos;</a></li>
												<li><a href="../../it/datasets/functions-dataset.html">Collezione di dataset &apos;Functions&apos;</a></li>
											</ul>
										</li>
										<li><a href="../../it/info.html">Info</a></li>
									</ul>
								</nav>

							<!-- Section -->
								<section>
                                    <div class="side-topics">
                                        <header class="align-center">
                                            <h2><a href="../../it/reti-neurali/">Reti&nbsp;Neurali</a></h2>
                                        </header>
                                        <article>
                                            <a href="../../it/reti-neurali/" class="image"><span class="icon solid fa-sitemap"/></a>
                                        </article>
                                        <header class="align-center">
                                            <h2><a href="../../it/computazione-quantistica/">Computazione&nbsp;Quantistica</a></h2>
                                        </header>
                                        <article>
                                            <a href="../../it/computazione-quantistica/" class="image"><span class="icon solid fa-atom"/></a>
                                        </article>
                                    </div>
								</section>

							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">
										Grafica basata sul template &apos;Editorial&apos; (con personalizzazione) scaricato da <a href="https://html5up.net" target="_blank">HTML5 UP</a>.
										<br/>
										Clicka sui link per vedere i file <a href="../../html5up-license/LICENSE.txt" target="_blank">LICENSE.txt</a> e <a href="../../html5up-license/README.txt" target="_blank">README.txt</a> del template &apos;Editorial&apos; di HTML5 UP.
										<br>
										<br>
										&copy; <a href="../../en/info.html">Ettore Messina</a>. 
									</p>
								</footer>
						</div>
					</div>
			</div>

		<!-- Scripts -->
			<script src="../../assets/js/jquery.min.js"></script>
			<script src="../../assets/js/browser.min.js"></script>
			<script src="../../assets/js/breakpoints.min.js"></script>
			<script src="../../assets/js/util.js"></script>
			<script src="../../assets/js/main.js"></script>

			<style>
				a.cc-link
				{
			    	border-bottom: none;
				}
				a.cc-link:hover
				{
					color: white !important;
				}
			</style>
	</body>
</html>

