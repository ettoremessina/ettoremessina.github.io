















<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>

		<script type="text/javascript" charset="UTF-8" src="//cookie-script.com/s/19e1626ea9f21a6fcc285b559b5957e6.js"></script>
		<script type="text/plain" data-cookiescript="accepted" data-cookiecategory="functionality" src="https://www.googletagmanager.com/gtag/js?id=UA-149444322-1"></script>
		<script>
			window.dataLayer = window.dataLayer || [];
			function gtag(){dataLayer.push(arguments);}
			gtag('js', new Date());

			gtag('config', 'UA-149444322-1');
		</script>


		<title>Mentalit&agrave;&nbsp;Computazionale - Approssimazione di una curva parametrica su un piano con TensorFlow</title>
		
		<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/railscasts.min.css">
		<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>
		<script>hljs.initHighlightingOnLoad();</script>
		<style>
			pre > code 
			{
				font-size: 1.2em;
			}
		</style>

		
		<script type="text/javascript" src="//latex.codecogs.com/latexit.js"></script>
		<script type="text/x-mathjax-config">
			MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
		</script>
		<script type="text/javascript"
			src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>



		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../../../assets/css/main.css" />
		<link rel="shortcut icon" href="../../../favicon.ico" type="image/x-icon" />
		<link rel="icon" href="../../../favicon.ico" type="image/x-icon" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="../../../it/info.html" class="logo"><strong>Mentalit&agrave;&nbsp;Computazionale</strong> di&nbsp;Ettore&nbsp;Messina</a>
									<div style="text-align:right">
										<a class="logo" href="../../../en/index.html">en</a>
										<a class="logo" href="../../../it/index.html">it</a>
									</div>
									<ul class="icons">
										<li><a href="https://github.com/ettoremessina" class="icon brands fa-github" target="_blank"><span class="label">GitHub</span></a></li>
										<li><a href="https://twitter.com/ettoremessina" class="icon brands fa-twitter" target="_blank"><span class="label">Twitter</span></a></li>
										<li><a href="https://www.facebook.com/MentalitaComputazionale" class="icon brands fa-facebook-f" target="_blank"><span class="label">Facebook</span></a></li>
										<li><a href="https://www.instagram.com/etmessina" class="icon brands fa-instagram" target="_blank"><span class="label">Instagram</span></a></li>
										<li><a href="https://www.linkedin.com/in/ettoremessina" class="icon brands fa-linkedin" target="_blank"><span class="label">LinkedIn</span></a></li>
										<li><a href="https://t.me/ettoremessina" class="icon brands fa-telegram" target="_blank"><span class="label">Skype</span></a></li>
										<li><a href="https://medium.com/@ettoremessina" class="icon brands fa-medium-m" target="_blank"><span class="label">Medium</span></a></li>
										<li><a href="skype:ettore-messina?chat" class="icon brands fa-skype" target="_blank"> <span class="label">Skype</span></a></li>
									</ul>
								</header>

<!-- Content -->
	<section>
		<header class="main">
			<h1>Approssimazione di una curva parametrica su un piano con TensorFlow</h1>
		</header>

		<p>
			Una curva parametrica con parametro $t$ appartenente ad un intervallo chiuso su un sistema di riferimento cartesiano $Oxy$ si definisce con una coppia di funzioni $x(t) \colon [a,b] \to \rm I\!R$ e $y(t) \colon [a,b] \to \rm I\!R$
			che restituiscono rispettivamente il valore della coordinata $x$ e della coordinata $y$ al variare del parametro $t$;
			equivalentemente una curva parametrica &egrave; definita anche con una funzione vettoriale $f(t) \colon [a,b] \to {\rm I\!R x \rm I\!R}$ tale che $$f(t) = \begin{bmatrix} x(t) \\ y(t) \\ \end{bmatrix}$$
			L&apos;approssimazione di una tale curva, se continua e limitata, con una rete neurale &egrave; un problema classico di machine learning e non richiede reti neurali con architeture sofisticate:
			&egrave; sufficiente utilizzare una architettura a <em>MLP</em> (percettrone multistrato, dall&apos;inglese Multi-Layer Perceptron) per ottenere risultati con precisione prossima al 100%.
			<br/>
			<br/>
			Si osservi intanto che le due definizioni di curva parametrica, seppur matematicamente equivalenti, suggeriscono due architetture di reti neurali differenti: la prima definizione conduce ad una coppia di MLP indipendenti, uno per approssimare $x(t)$ e l&apos;altro per approssimare $y(t)$
			per poi combinare i risultati in uscita dalle due reti e ottenere le coppie $(x,y)$ che approssimano la curva sul piano;
			la seconda definizione suggerisce invece un MLP ove il layer di input contiene un solo neurone in quando la dimensione del dominio &egrave; 1 (l&apos;intervallo $[a,b]$) 
			mentre il layer di output contiente 2 neuroni in quanto la dimensione del codominio &egrave; 2.

			<br/>
			Come gi&agrave; osservato nel post <a href="../../../it/posts/reti-neurali/approssimazione-di-una-funzione-di-una-variabile-con-tensorflow.html">Approssimazione di una funzione di una variabile con TensorFlow</a>, su Internet si trovano numerosi esempi di MLP che approssimano curve; 
			tuttavia spesso tali esempi combinano in un unico script Python la generazione dei dataset, il training, la predizione e la visualizzazione della curva approssimata;
			inoltre l&apos;architettura &egrave; spesso hardcoded o poco parametrizzabile da linea di comando e infine le funzioni di attivazione, l&apos;algoritmo di ottimizzazione usato e la funzione di loss sono decisi dall&apos;autore 
			senza una spiegazione che descriva le motivazioni della loro scelta.
			<br/>
			La scarsa parametrizzazione, il ricorso a scelte implementate hardcoded e l&apos;unificazione di varie funzionalit&agrave; in un unico script rendono poco agevole la sperimentazione
			e costringono lo sperimentatore a procedere per modifiche di codice al fine di realizzare e testare personalizzazioni degli MLP coinvolti e/o delle procedure di addestramento.
		</p>
		<p>
			Scopo di questo post e del relativo codice, disponibile su <a target="_blank" href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/tree/master/parametric-curve-on-plane-fitting">GitHub</a>, &egrave; di consentire allo sperimentatore di implementare e testare diverse combinazioni
			di architettura MLP, funzioni di attivazione, algoritmo di addestramento e funzione di loss senza scrivere codice ma agendo solamente sulla linea di comando di quattro script Python (di cui uno scritto in due varianti in accordo con le due strutture di rete suggerite prima) 
			che implementano separatamente le seguenti funzionalit&agrave;:
			<ul>
				<li>
					<b>Creazione dei dataset</b>: generazione di un file csv a partire da una coppia di funzioni $x(t) \colon [a,b] \to \rm I\!R$ e $y(t) \colon [a,b] \to \rm I\!R$ passate come argomento (quindi <u>non</u> hardcoded). Questa fase &egrave; opzionale in quanto i dataset potrebbero pre-esistere
					(come avviene nel mondo reale ad esempio estraendo curve da dati presenti su database o file Excel, dall&apos;output di strumenti di misura, dai data-logger collegati a sensori elettronici, ecc)
					e quindi non necessariamente essere generati in modo sintetico.
				</li>
				<li>
					<b>Definizione dell&apos;architettura del MLP + Addestramento</b>: configurazione dell&apos;architettura degli strati nascosti del/degli MLP con le relative funzioni di attivazione in uscita ed esecuzione della procedura di addestramento sul dataset di training consentendo di specificare la scelta dell&apos;algoritmo di ottimizzazione, della funzione di loss
					e di altri parametri di addestramento. Questa funzionalit&agrave; &egrave; implementata in due alternative varianti: una variante per realizzare una coppia di MLP che approssimano le singole funzioni componenti, l&apos;altra variante alternativa per implementare un MLP che approssima la funzione vettoriale.
				</li>
				<li>
					<b>Predizione</b>: applicazione del modello precedentemente addestrato al dataset di test (che contiene dati mai visti dal modello in fase di addestramento) e generazione di un file csv di uscita con la predizione.
				</li>
				<li>
					<b>Visualizzazione del risultato</b>: generazione di un grafico che mostra la curva del dataset iniziale (training o test) e quella della predizione e consente la comparazione visuale delle due curve. Questa fase &egrave; opzionale in quanto la predizione &egrave; salvata al passo precedente in un file csv ed &egrave; quindi gi&agrave; utilizzabile come tale.
				</li>
			</ul>
			Il codice descritto da questo post richiede la versione 3 di Python ed utilizza la tecnologia TensorFlow 2 (sia per CPU che per GPU) con Keras (che &egrave; gi&agrave; integrato dentro TensorFlow 2) per realizzare il/gli MLP e l&apos;addestramento.
			Il codice richiede inoltre le librerie NumPy e MatPlotLib.
			<br/>
			Lo stesso identico meccanismo &egrave; stato realizzato usando la tecnologia PyTorch; si veda il post <a href="../../../it/posts/reti-neurali/approssimazione-di-una-curva-sul-piano-con-pytorch.html">Approssimazione di una curva parametrica su un piano con PyTorch</a> pubblicato sempre su questo sito web.
		</p>

		<h2>Creazione dei dataset</h2>
		<p>
			Scopo del programma Python <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/parametric-curve-on-plane-fitting/pmc2t_gen.py" target="_blank"><code>pmc2t_gen.py</code></a>
			&egrave; di generare i dataset (di training e/o di test) da utilizzare nelle fasi successive;
			prende in linea di comando (in sintassi <em>lambda body</em>) le due funzioni componenti $x(t)$ e $y(t)$ da approssimare, l&apos;intervallo della variabile indipendente $t$ (inizio, fine e passo di discretizzazione)
			e genera il dataset in un file nel formato csv applicando le due funzioni all&apos;intervallo passato.
			<br/>
			Il file csv in uscita ha infatti tre colonne (senza header): la prima colonna contiene i valori, ordinati in modo crescente, della variabile indipendente $t$ nell&apos;intervallo desiderato con il passo di discretizzazione specificato;
			la seconda colonna contiene i valori della variabile dipendente $x$, ovverosia i valori della funzione $x(t)$ corrispondenti al valore di $t$ della prima colonna e
			la terza colonna contiene i valori della variabile dipendente $y$, ovverosia i valori della funzione $y(t)$ corrispondenti sempre al valore di $t$ della prima colonna.
			<br/>
			<br/>
			Per ottenere l&apos;usage del programma &egrave; sufficiente eseguire il seguente comando:
			<pre><code class="shell">$ python pmc2t_gen.py --help</code></pre>
			e l&apos;output ottenuto &egrave;:
			<br/>
			<br/>
			<pre><code class="shell">usage: pmc2t_gen.py [-h] 
-h, --help                  show this help message and exit
--dsout DS_OUTPUT_FILENAME  dataset output file (csv format)
--xt FUNC_X_BODY            x(t) body (body lamba format)
--yt FUNC_X_BODY            y(t) body (body lamba format)
--rbegin RANGE_BEGIN        begin range (default:-5.0)
--rend RANGE_END            end range (default:+5.0)
--rstep RANGE_STEP          step range (default: 0.01)</code></pre>
			Si rimanda alla lettura del file <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/parametric-curve-on-plane-fitting/README.md" target="_blank">README.md</a> per il dettaglio esaustivo della semantica dei parametri supportati in linea di comando.
			<br/>
		</p>
		<h3>Un esempio di uso del programma pmc2t_gen.py</h2>
		<p>
			Si supponga di voler approssimare nell&apos;intervallo $[0.0,20.0]$ la spirale di Archimede, che &egrave; rappresentata dalla seguente coppia di funzioni
			$$x(t) = kt \cos t$$
			$$y(t) = kt \sin t$$ 
			$$k=\frac{1}{10}$$
			Tenendo presente che <em>np</em> &egrave; l&apos;alias della libreria NumPy, queste si traducono in sintassi lambda body Python cos&igrave;:
			<pre><code class="python">0.1 * t * np.cos(t)
0.1 * t * np.sin(t)</code></pre>
			Per generare il dataset di training, si esegua quindi il seguente comando:
			<br/>
			<br/>
			<pre><code class="shell">$ python pmc2t_gen.py \
  --dsout mytrain.csv \
  --xt "0.1 * t * np.cos(t)" \
  --yt "0.1 * t * np.sin(t)" \
  --rbegin 0.0 \
  --rend 20.0 \
  --rstep 0.01</code></pre>
			mentre per generare il dataset di test, si esegua il seguente comando:
			<br/>
			<br/>
			<pre><code class="shell">$ python pmc2t_gen.py \
  --dsout mytest.csv \
  --xt "0.1 * t * np.cos(t)" \
  --yt "0.1 * t * np.sin(t)" \
  --rbegin -20.0 \
  --rend 20.0 \
  --rstep 0.0475</code></pre>
			Si osservi che il passo di discretizzazione del dataset di test &egrave; pi&ugrave; grande di quello di training e questo &egrave; normale 
			in quanto l&apos;addestramento, per essere accurato, deve essere eseguito su una maggiore quantit&agrave; di dati.
			Inoltre si osservi che &egrave; opportuno che il passo di discretizzazione del dataset di test <u>non</u> sia un multiplo di quello di training
			per garantire che il dataset di test contenga la maggior parte dei dati non presenti nel dataset di training, e questo rende pi&ugrave; interessante la predizione.
		</p>

		<h2>Definizione dell&apos;architettura del MLP + Addestramento</h2>
		<p>
			Scopo dei due alternativi Python <code>pmc2td_fit.py</code> e <code>pmc2ts_fit.py</code> Ã¨ quello di creare dinamicamente il/gli MLP in accordo con i parametri passati in linea di comando ed addestrarlo/i.
			Precisamete:
			<ul>
				<li>
					Il programma <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/parametric-curve-on-plane-fitting/pmc2td_fit.py" target="_blank"><code>pmc2td_fit.py</code></a>
					crea dinamicamente una coppia di MLP, strutturalmente identici, in accordo con i parametri passati in linea di comando e li addestra separatamente: il primo MLP &egrave; addestrato sulla funzione $x(t)$ e il secondo MLP addestrato sulla funzione $y(t)$.
				</li>
				<li>
					Il programma <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/parametric-curve-on-plane-fitting/pmc2ts_fit.py" target="_blank"><code>pmc2ts_fit.py</code></a>
					crea dinamicamente un MLP in accordo con i parametri passati in linea di comando e lo addestra sulla funzione vettoriale $f(t) = \beginbmatrix x(t) \\ y(t) \\ \endbmatrix$.
				</li>
			</ul>	
			Per ottenere l&apos;usage di ciascuno dei due programmi &egrave; sufficiente eseguire il seguente comando:
			<pre><code class="shell">$ python pmc2td_fit.py --help</code></pre>
			oppure
			<pre><code class="shell">$ python pmc2ts_fit.py --help</code></pre>
			e l&apos;output ottenuto &egrave;:
			<br/>
			<br/>
			<pre><code class="shell">usage: fx_fit.py [-h]
--trainds TRAIN_DATASET_FILENAME
--modelout MODEL_PATH
[--epochs EPOCHS]
[--batch_size BATCH_SIZE]
[--learning_rate LEARNING_RATE]
[--hlayers HIDDEN_LAYERS_LAYOUT [HIDDEN_LAYERS_LAYOUT ...]]
[--hactivations ACTIVATION_FUNCTIONS [ACTIVATION_FUNCTIONS ...]]
[--optimizer OPTIMIZER]
[--loss LOSS]</code></pre>
			Si rimanda alla lettura del file <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/parametric-curve-on-plane-fitting/README.md" target="_blank">README.md</a> per il dettaglio esaustivo della semantica dei parametri supportati in linea di comando.
			<br/>
		</p>
		<h3>Un esempio di uso del programma pmc2td_fit.py</h2>
		<p>
			Si supponga di avere a disposizione un dataset di training (ad esempio generato tramite <code>pmc2td_gen.py</code> come mostrato nel paragrafo precedente)
			e si voglia che il MLP abbia due layer nascosti rispettivamente con 200 e 200 neuroni e che si voglia usare la funzione di attivazione sigmoid in uscita da tutti e tre i layer;
			inoltre si vogliano eseguire 1000 epoche di training con un batch size di 200 elementi usando l&apos;algoritmo di ottimizzazione Adamax con un learning rate di 0.02 
			e la MeanSquaredError quale funzione di loss. Per mettere in azione tutto questo si esegua il seguente comando:
			<br/>
			<br/>
			<pre><code class="shell">$ python pmc2td_fit.py \
  --trainds mytrain.csv \
  --modelout mymodeld \
  --hlayers 200 300 200
  --hactivation sigmoid sigmoid sigmoid \
  --epochs 1000 \
  --batch_size 200 \
  --optimizer 'Adamax()' \
  --learning_rate 0.02 \
  --loss 'MeanSquaredError()'</code></pre>
			al termine del quale la cartella <code>mymodeld</code> conterr&agrave; i due modelli di MLP addestrati sul dataset <code>mytrain.csv</code> secondo i parametri passati in linea di comando.
		</p>
		<h3>Un esempio di uso del programma pmc2ts_fit.py</h2>
		<p>
			Per eseguire <code>pmc2td_fit.py</code> con gli stessi parametri usati nell&apos;esempio precedente, si esegua il seguente comando:
			<br/>
			<br/>
			<pre><code class="shell">$ python pmc2td_fit.py \
  --trainds mytrain.csv \
  --modelout mymodels \
  --hlayers 200 300 200
  --hactivation sigmoid sigmoid sigmoid \
  --epochs 1000 \
  --batch_size 200 \
  --optimizer 'Adamax()' \
  --learning_rate 0.02 \
  --loss 'MeanSquaredError()'</code></pre>
			al termine del quale la cartella <code>mymodels</code> conterr&agrave; il modello del singolo MLP addestrato sul dataset <code>mytrain.csv</code> secondo i parametri passati in linea di comando.
		</p>

		<h2>Predizione</h2>
		<p>
			Scopo del programma Python <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/parametric-curve-on-plane-fitting/fx_predict.py" target="_blank"><code>fx_predict.py</code></a>
			&egrave; quello di applicare il modello di MLP generato tramite <code>fx_fit.py</code> al dataset di test (ad esempio generato tramite <code>fx_gen.py</code> come mostrato in un paragrafo precedente);
			l&apos;esecuzione del programma produce in uscita un file csv con due colonne (senza header): la prima colonna contiene i valori della variabile indipendente $x$ presi dal dataset di test
			e la seconda colonna contiene i valori predetti della variabile dipendente, ovverosia i valori della predizione che approssimano la funzione $f(x)$ corrispondenti al valore di $x$ della prima colonna.
			<br/>
			Per ottenere l&apos;usage del programma &egrave; sufficiente eseguire il seguente comando:
			<pre><code class="shell">$ python fx_predict.py --help</code></pre>
			e l&apos;output ottenuto &egrave;:
			<br/>
			<br/>
			<pre><code class="shell">usage: fx_predict.py [-h]
--model MODEL_PATH
--testds TEST_DATASET_FILENAME
--predictedout PREDICTED_DATA_FILENAME</code></pre>
			Si rimanda alla lettura del file <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/parametric-curve-on-plane-fitting/README.md" target="_blank">README.md</a> per il dettaglio esaustivo della semantica dei parametri supportati in linea di comando.
			<br/>
		</p>
		<h3>Un esempio di uso del programma fx_predict.py</h2>
		<p>
			Si supponga di avere a disposizione il dataset di test <code>mytest.csv</code> (ad esempio generato tramite <code>fx_gen.py</code> come mostrato in un paragrafo precedente)
			e il modello di MLP addestrato nella cartella <code>mymodel</code> (generato tramite <code>fx_fit.py</code> come mostrato nell&apos;esempio del paragrafo precedente); si esegua quindi il seguente comando:
			<br/>
			<br/>
			<pre><code class="shell">$ python fx_predict.py \
  --model mymodel \
  --testds mytest.csv \
  --predictedout myprediction.csv
</code></pre>
			al termine del quale il file <code>myprediction.csv</code> conterr&agrave; l&apos;approssimazione della funzione iniziale.
		</p>

		<h2>Visualizzazione del risultato</h2>
		<p>
			Scopo del programma Python <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/parametric-curve-on-plane-fitting/fx_plot.py" target="_blank"><code>fx_plot.py</code></a>
			&egrave; quello di visualizzare la curva della predizione sovrapposta alla curva del dataset iniziale (che sia quello di test o di training) e questo consente la comparazione visuale delle due curve.
			<br/>
			Per ottenere l&apos;usage del programma &egrave; sufficiente eseguire il seguente comando:
			<pre><code class="shell">$ python fx_plot.py --help</code></pre>
			e l&apos;output ottenuto &egrave;:
			<br/>
			<br/>
			<pre><code class="shell">usage: fx_plot.py [-h]
--ds DATASET_FILENAME
--predicted PREDICTED_DATA_FILENAME
[--savefig SAVE_FIGURE_FILENAME]</code></pre>
			Si rimanda alla lettura del file <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/blob/master/parametric-curve-on-plane-fitting/README.md" target="_blank">README.md</a> per il dettaglio esaustivo della semantica dei parametri supportati in linea di comando.
			<br/>
		</p>
		<h3>Un esempio di uso del programma fx_plot.py</h2>
		<p>
			Avendo a disposizione il dataset di test <code>mytest.csv</code> (ad esempio generato tramite <code>fx_gen.py</code> come mostrato in un paragrafo precedente)
			e il file csv della predizione (generato tramite <code>fx_predict.py</code> come mostrato nel precedente paragrafo), per generare i due grafici si esegua il seguente comando:
			<br/>
			<br/>
			<pre><code class="shell">$ python fx_plot.py \
  --ds mytest.csv \
  --predicted myprediction.csv</code></pre>
			che mostra le due curve sovrapposte: in blu quella del dataset di test, in rosso quella della predizione.
			<br/>
			<b>Nota</b>: Data la natura stocastica della fase di addestramento, i singoli specifici risultati possono variare. Si consideri di eseguire la fase di addestramento pi&ugrave; volte.
		</p>
		<div class="betweentextlines"><img src="../../../posts/neural-networks/parametric-curve-on-plane-fitting-with-tensorflow/nn-pcopfwtf-example09.png" /></div>
		<div class="photocaption">Grafico generato dal programma <code>fx_plot.py</code> che mostra l&apos;approssimazione effettuata dal MLP della funzione $f(x)=\frac{\sin 2x}{e^\frac{x}{5}}$</div>
		<br/>

		<h2>Esempi di uso in cascata dei quattro programmi</h2>
		<p>
			Nella cartella <a href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/tree/master/parametric-curve-on-plane-fitting/examples" target="_blank"><code>parametric-curve-on-plane-fitting/examples</code></a>
			ci sono nove script shell che mostrano l&apos;uso dei quattro programmi in cascata in varie combinazioni
			di parametri (architettura del MLP, funzioni di attivazione, algoritmo, funzione di loss, parametri di prodedura di training).
			Per mandare in esecuzione i nove esempi eseguire i seguenti comandi:
<pre><code class="shell">$ cd parametric-curve-on-plane-fitting/examples
$ sh example1.sh
$ sh example2.sh
$ sh example3.sh
$ sh example4.sh
$ sh example5.sh
$ sh example6.sh
$ sh example7.sh
$ sh example8.sh
$ sh example9.sh</code></pre>
			<b>Nota</b>: Data la natura stocastica di questi esempi (relativamente alla parte di training), i singoli specifici risultati possono variare. Si consideri di eseguire i singoli esempi pi&ugrave; volte.
		</p>

		<h2>Download del codice completo</h2>
		<p>
			Il codice completo &egrave; disponibile su <a target="_blank" href="https://github.com/ettoremessina/fitting-with-mlp-using-tensorflow/tree/master/parametric-curve-on-plane-fitting">GitHub</a>.
			<br/>
			
			Questo materiale &egrave; distribuito su licenza MIT; sentiti libero di usare, condividere, &quot;forkare&quot; e adattare tale materiale come credi.
			<br/>
			Sentiti anche libero di pubblicare pull-request e bug-report su questo repository di GitHub oppure di contattarmi sui miei canali social disponibili nell'angolo in alto a destra di questa pagina. 
			<br/>

		</p>

	</section>

						</div>
				</div>
				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">
							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="../../../it/index.html">Home</a></li>
										<li>
											<span class="opener">Reti&nbsp;Neurali</span>
											<ul>
												<li><a href="../../../it/posts/reti-neurali/approssimazione-di-una-funzione-di-una-variabile-con-tensorflow.html">Approssimazione di una funzione di una variabile con TensorFlow</a></li>
												<li><a href="../../../it/posts/reti-neurali/approssimazione-di-una-funzione-di-una-variabile-con-pytorch.html">Approssimazione di una funzione di una variabile con PyTorch</a></li>
												<li><a href="../../../it/posts/reti-neurali/approssimazione-di-una-curva-sul-piano-con-tensorflow.html">Approssimazione di una curva parametrica su un piano con TensorFlow</a></li>
												<li><a href="../../../it/posts/reti-neurali/approssimazione-di-una-curva-sul-piano-con-pytorch.html">Approssimazione di una curva parametrica su un piano con PyTorch</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Computazione&nbsp;Quantistica</span>
											<ul>
												<li><a href="../../../it/posts/computazione-quantistica/porte-hadamard-in-cascata.html">Porte Hadamard in cascata</a></li>
												<li><a href="../../../it/posts/computazione-quantistica/generazione-numero-casuale.html">Generazione di un numero casuale</a></li>
											</ul>
										</li>
										<li>
											<span class="opener">Dataset</span>
											<ul>
												<li><a href="../../../it/posts/datasets/synthetic-words-dataset.html">Synthetic Words</a></li>
											</ul>
										</li>
										<li><a href="../../../it/info.html">Info</a></li>
									</ul>
								</nav>

							<!-- Section -->
								<section>
                                    <div class="side-topics">
                                        <header class="major">
                                            <h2><a href="../../../it/reti-neurali.html">Reti&nbsp;Neurali</a></h2>
                                        </header>
                                        <article>
                                            <a href="../../../it/reti-neurali.html" class="image"><span class="icon solid fa-sitemap"/></a>
											<p>
	Studi, esperimenti ed esempi di modelli di apprendimento automatico profondo basati su reti neurali di diverse tipologie: percettroni multistrato, convoluzionali, ricorrenti, long-short-term-memory.
	Applicazioni delle reti neurali all'approssimazione di oggetti matematici, all'analisi di testi, immagini, suoni e video, alla ricerca di pattern ricorrenti in serie numeriche.
	Codice rigorosamente originale scritto in Python 3 con TensorFlow e/o PyTorch, funzionante e liberamente disponibile su <a href="https://github.com/ettoremessina" target="_blank">GitHub</a>.
</p>
                                        </article>
                                        <header class="major">
                                            <h2><a href="../../../it/computazione-quantistica.html">Computazione&nbsp;Quantistica</a></h2>
                                        </header>
                                        <article>
                                            <a href="../../../it/computazione-quantistica.html" class="image"><span class="icon solid fa-atom"/></a>
											<p>
	Studi, esperimenti ed esempi di programmi scritti per computer quantistici e simulatori. Algoritmi che sfruttano le porte quantistiche, la sovrapposizione degli stati dei qubit, l'entanglement, 
	il collasso della misura. Analisi dei risultati ottenuti dall'esecuzione di programmi su computer quantistici reali.
	Codice rigorosamente originale scritto nei linguaggi pi&ugrave; comuni per la programmazione quantistica quali QASM, Q# e Python con Qiskit, funzionante e liberamente disponibile su <a href="https://github.com/ettoremessina" target="_blank">GitHub</a>.
</p>
                                        </article>
                                    </div>
								</section>

							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">
										Grafica basata sul template &apos;Editorial&apos; (con personalizzazione) scaricato da <a href="https://html5up.net" target="_blank">HTML5 UP</a>.
										<br/>
										Clicka sui link per vedere i file <a href="../../../html5up-license/LICENSE.txt" target="_blank">LICENSE.txt</a> e <a href="../../../html5up-license/README.txt" target="_blank">README.txt</a> del template &apos;Editorial&apos; di HTML5 UP.
										<br>
										<br>
										&copy; <a href="../../../en/info.html">Ettore Messina</a>. 
									</p>
								</footer>
						</div>
					</div>
			</div>

		<!-- Scripts -->
			<script src="../../../assets/js/jquery.min.js"></script>
			<script src="../../../assets/js/browser.min.js"></script>
			<script src="../../../assets/js/breakpoints.min.js"></script>
			<script src="../../../assets/js/util.js"></script>
			<script src="../../../assets/js/main.js"></script>

			<style>
				a.cc-link
				{
			    	border-bottom: none;
				}
				a.cc-link:hover
				{
					color: white !important;
				}
			</style>


	</body>
</html>

